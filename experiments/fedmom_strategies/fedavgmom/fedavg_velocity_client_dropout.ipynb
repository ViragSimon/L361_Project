{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity demo\n",
    "Current approach shares full optimizer state between rounds. Optimizer states are aggregated when received on server end and then shared out such that all clients begin the next round with the aggregated optimizer state.\n",
    "Limitations: \n",
    "- We are not measuring communication from this, but if desired, it should be pretty easy to add\n",
    "- Currently, we share the entire optimizer state, but when training only a single layer, we would only need to share the state related to that layer. To only share updated layer, modify _aggregate_optimizer_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mps\n",
      "Flower 1.15.2 / PyTorch 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple, Union, Callable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import sys\n",
    "import base64\n",
    "import pickle\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr.server.strategy import Strategy\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context, Status, GetParametersRes, Parameters, GetParametersIns, MetricsAggregationFn,NDArrays,Scalar\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents \n",
    "from flwr.server.strategy import FedAvg, FedProx\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    ParametersRecord,\n",
    "    parameters_to_ndarrays,\n",
    "    array_from_numpy\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = \"mps\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        \n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters, trainable_layers=-1):\n",
    "    \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n",
    "    current_state = OrderedDict(net.state_dict())\n",
    "    \n",
    "    if trainable_layers == -1:\n",
    "        # Update all parameters\n",
    "        params_dict = zip(current_state.keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "    else:\n",
    "        # Only update the specified layer's parameters\n",
    "        # Convert current state to numpy arrays\n",
    "        numpy_state = [param.cpu().numpy() for param in current_state.values()]\n",
    "        \n",
    "        # Update the specific indices with new parameters\n",
    "        numpy_state[trainable_layers*2] = parameters[0]\n",
    "        numpy_state[trainable_layers*2 + 1] = parameters[1]\n",
    "        \n",
    "        # Convert back to torch and update state dict\n",
    "        for idx, key in enumerate(current_state.keys()):\n",
    "            current_state[key] = torch.from_numpy(numpy_state[idx])\n",
    "        \n",
    "        net.load_state_dict(current_state, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int, optimizer=None):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    print(f\"training network...\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "        \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "        trainable_layers_set = []\n",
    "        if trainable_layers == -1:\n",
    "            trainable_layers_set = [-1]\n",
    "        else:\n",
    "            trainable_layers_set = [trainable_layers *2, trainable_layers *2 +1]\n",
    "\n",
    "        for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "            \n",
    "            if idx in trainable_layers_set or trainable_layers_set[0] == -1:\n",
    "                param.requires_grad = True\n",
    "                print(f\"layer index is {idx} and name{name} is trainabe\")\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                print(f\"layer index is {idx} and name{name} is frozen\")\n",
    "\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n",
    "\n",
    "def serialize_optimizer_state(state_dict):\n",
    "    \"\"\"Serialize optimizer state with reduced memory footprint\"\"\"\n",
    "    lightweight_state = {'state': {}, 'param_groups': state_dict['param_groups']}\n",
    "    \n",
    "    for k, v in state_dict['state'].items():\n",
    "        lightweight_state['state'][k] = {\n",
    "            'exp_avg': v['exp_avg'].clone().detach().cpu().half().numpy(),  # Use half precision\n",
    "            'exp_avg_sq': v['exp_avg_sq'].clone().detach().cpu().half().numpy(),\n",
    "            'step': v['step'].item()  # Store as scalar instead of tensor\n",
    "        }\n",
    "    \n",
    "    return base64.b64encode(pickle.dumps(lightweight_state, protocol=pickle.HIGHEST_PROTOCOL)).decode('ascii')\n",
    "\n",
    "def deserialize_optimizer_state(serialized_state):\n",
    "    \"\"\"Deserialize and reconstruct optimizer state\"\"\"\n",
    "    state_dict = pickle.loads(base64.b64decode(serialized_state))\n",
    "    reconstructed_state = {'state': {}, 'param_groups': state_dict['param_groups']}\n",
    "    \n",
    "    for k, v in state_dict['state'].items():\n",
    "        reconstructed_state['state'][k] = {\n",
    "            'exp_avg': torch.tensor(v['exp_avg'], dtype=torch.float32),\n",
    "            'exp_avg_sq': torch.tensor(v['exp_avg_sq'], dtype=torch.float32),\n",
    "            'step': torch.tensor(v['step'])\n",
    "        }\n",
    "    \n",
    "    return reconstructed_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NETWORK_LEN = len(Net().state_dict().keys()) // 2\n",
    "EPOCHS = 8\n",
    "NUM_PARTITIONS = 3\n",
    "NUM_OF_CYCLES  = 1\n",
    "NUM_OF_FULL_UPDATES_BETWEEN_CYCLES = 2\n",
    "NUM_OF_ROUNDS = (NUM_OF_CYCLES * NUM_OF_FULL_UPDATES_BETWEEN_CYCLES) + (NUM_OF_CYCLES * NETWORK_LEN *2)\n",
    "print(f\"Number of rounds: {NUM_OF_ROUNDS}\")\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays, Scalar\n",
    "\n",
    "def get_evaluate_fn(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutClientManager(SimpleClientManager):\n",
    "    \"\"\"Custom ClientManager that simulates client dropouts.\"\"\"\n",
    "    def __init__(self, dropout_rate: float = 0.4):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        num_clients: int,\n",
    "        min_num_clients: Optional[int] = None,\n",
    "    ) -> List[ClientProxy]:\n",
    "        \"\"\"Sample clients and simulate dropouts.\"\"\"\n",
    "        # Get list of clients from parent class\n",
    "        clients = super().sample(num_clients, min_num_clients)\n",
    "        \n",
    "        # Randomly drop clients based on dropout rate\n",
    "        num_dropouts = int(len(clients) * self.dropout_rate)\n",
    "        if num_dropouts > 0:\n",
    "            dropout_indices = np.random.choice(\n",
    "                len(clients), \n",
    "                size=num_dropouts, \n",
    "                replace=False\n",
    "            )\n",
    "            clients = [c for i, c in enumerate(clients) if i not in dropout_indices]\n",
    "        \n",
    "        return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvg with velocity from global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "fed_part_avg_result = {}\n",
    "fed_part_avg_model_results = {}\n",
    "\n",
    "class FedPartAvgWithVelocity(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "\n",
    "        self.layer_update_strategy = layer_update_strategy  # 'sequential' or 'cyclic'\n",
    "        self.current_layer = 0  # Track which layer to update\n",
    "        self.number_of_layers = None\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "        self.updated_layers = -1\n",
    "        self.global_optim_state = None\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartAvgWithVelocity\"\n",
    "    \n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "    \n",
    "    def generate_layer_training_sequence(self) -> List[int]:\n",
    "        \"\"\"Generate a sequence of layers to train.\"\"\"\n",
    "        layer_training_sequence = []\n",
    "        for _ in range(NUM_OF_CYCLES):\n",
    "            for _ in range(NUM_OF_FULL_UPDATES_BETWEEN_CYCLES):\n",
    "                    layer_training_sequence.append(-1)\n",
    "            for layer in range(NETWORK_LEN):\n",
    "                    layer_training_sequence.append(layer)\n",
    "                    layer_training_sequence.append(layer)\n",
    "\n",
    "        return layer_training_sequence\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        self.layer_training_sequence = self.generate_layer_training_sequence()\n",
    "        self.number_of_layers = len(ndarrays)\n",
    "        self.latest_parameters = ndarrays_to_parameters(ndarrays)\n",
    "        self.latest_parameters = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_part_avg_model_results:  \n",
    "            expand_fed_part_avg_model_results= {**fed_part_avg_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_part_avg_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_part_avg_model_results[server_round] = expand_fed_part_avg_model_results\n",
    "        \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {\"trainable_layers\": self.layer_training_sequence[self.training_sequence_index], \"updated_layers\": self.updated_layers}\n",
    "\n",
    "        if self.global_optim_state is not None:\n",
    "            config[\"optimizer_state\"] = self.global_optim_state\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        print(f\"Training on layer {self.layer_training_sequence}\")\n",
    "        fit_configurations = []\n",
    "\n",
    "        params_array = parameters_to_ndarrays(parameters)\n",
    "        \n",
    "        # If doing full model update, send all parameters\n",
    "        if self.layer_training_sequence[self.training_sequence_index] == -1 or self.updated_layers == -1:\n",
    "            selected_params = parameters\n",
    "        else:\n",
    "            layer_idx = self.updated_layers\n",
    "            selected_params = ndarrays_to_parameters([\n",
    "                    params_array[layer_idx * 2],     # Weight\n",
    "                    params_array[layer_idx * 2 + 1]  # Bias\n",
    "                ])\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(selected_params, config)))\n",
    "\n",
    "        self.updated_layers = self.layer_training_sequence[self.training_sequence_index]\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        global global_all_optimizer_states\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters)\n",
    "            total_size += fit_res.metrics[\"recieved_parameter_size\"]\n",
    "\n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        if fed_part_avg_result.get(server_round):\n",
    "            fed_part_avg_result[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_part_avg_result[server_round] = {\"total_size\": total_size}\n",
    "        \n",
    "\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        trained_layer = results[0][1].metrics[\"trained_layer\"]\n",
    "        print(f\"aggregated weight size {len(aggregated_weights)} \")\n",
    "\n",
    "        if trained_layer == -1:\n",
    "            self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "        else:\n",
    "            current_model = parameters_to_ndarrays(self.latest_parameters)\n",
    "            print(f\"updateing layers {trained_layer* 2}  and {trained_layer* 2 + 1} \")\n",
    "            current_model[trained_layer* 2] = aggregated_weights[0]\n",
    "            current_model[trained_layer* 2 +1] = aggregated_weights[1]\n",
    "            self.latest_parameters = ndarrays_to_parameters(current_model)\n",
    "\n",
    "        # include optimizer state in metrics\n",
    "        metrics = {}\n",
    "        optimizer_states_serialized = [res.metrics.get(\"optimizer_state\", None) for _, res in results]\n",
    "        optimizer_states = [deserialize_optimizer_state(state) for state in optimizer_states_serialized if state is not None]\n",
    "        aggregated_optimizer_state = self._aggregate_optimizer_states(optimizer_states)\n",
    "        aggregated_optimizer_state_serialized = serialize_optimizer_state(aggregated_optimizer_state)\n",
    "        metrics[\"optimizer_state\"] = aggregated_optimizer_state_serialized\n",
    "        self.global_optim_state = aggregated_optimizer_state_serialized\n",
    "\n",
    "        return self.latest_parameters, metrics\n",
    "\n",
    "\n",
    "    def _aggregate_optimizer_states(self, optimizer_states):\n",
    "        # aggregates by comuting (unweighted) mean of 1st and 2nd momentum, and taking the maximum step value. (alternatively, could be changed to reset steps to 0)\n",
    "        \"\"\"Aggregate optimizer states with reduced memory usage\"\"\"\n",
    "        if not optimizer_states:\n",
    "            return None\n",
    "            \n",
    "        # Start with an empty state dict structure\n",
    "        aggregated_state_dict = {'state': {}, 'param_groups': optimizer_states[0]['param_groups']}\n",
    "        \n",
    "        # Get all layer keys\n",
    "        all_layers = list(optimizer_states[0]['state'].keys())\n",
    "        \n",
    "        for layer in all_layers:\n",
    "            # Initialize with zeros instead of stacking\n",
    "            if layer not in aggregated_state_dict['state']:\n",
    "                aggregated_state_dict['state'][layer] = {}\n",
    "                \n",
    "            # Get shape from first optimizer\n",
    "            exp_avg_shape = optimizer_states[0]['state'][layer]['exp_avg'].shape\n",
    "            exp_avg_sq_shape = optimizer_states[0]['state'][layer]['exp_avg_sq'].shape\n",
    "            \n",
    "            # Pre-allocate tensors\n",
    "            sum_exp_avg = torch.zeros(exp_avg_shape, device='cpu')\n",
    "            sum_exp_avg_sq = torch.zeros(exp_avg_sq_shape, device='cpu')\n",
    "            max_step = 0\n",
    "            \n",
    "            # Sum without stacking\n",
    "            for state in optimizer_states:\n",
    "                if layer in state['state']:\n",
    "                    sum_exp_avg += state['state'][layer]['exp_avg'].cpu()\n",
    "                    sum_exp_avg_sq += state['state'][layer]['exp_avg_sq'].cpu()\n",
    "                    max_step = max(max_step, state['state'][layer]['step'].item())\n",
    "            \n",
    "            # Average\n",
    "            n_states = len(optimizer_states)\n",
    "            aggregated_state_dict['state'][layer] = {\n",
    "                'exp_avg': sum_exp_avg / n_states,\n",
    "                'exp_avg_sq': sum_exp_avg_sq / n_states,\n",
    "                'step': torch.tensor(max_step)\n",
    "            }\n",
    "        \n",
    "        return aggregated_state_dict\n",
    "\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_part_avg_result.get(server_round):\n",
    "            fed_part_avg_result[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_part_avg_result[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgPartWithVelocityFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, context: Context):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.client_state = context.state\n",
    "    \n",
    "        # Initialize parameters record if it doesn't exist\n",
    "        if \"net_parameters\" not in self.client_state.parameters_records:\n",
    "            self.client_state.parameters_records[\"net_parameters\"] = ParametersRecord()\n",
    "            # Save initial model state\n",
    "            self._save_model_state()\n",
    "\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        if config[\"trainable_layers\"] == -1:\n",
    "            trained_layers = parameters\n",
    "        else:\n",
    "            trained_layers = [\n",
    "                parameters[config[\"trainable_layers\"] * 2],\n",
    "                parameters[config[\"trainable_layers\"] * 2 + 1]\n",
    "            ]\n",
    "        \n",
    "        return trained_layers\n",
    "\n",
    "    def _save_model_state(self):\n",
    "        \"\"\"Save current model parameters to context\"\"\"\n",
    "        p_record = ParametersRecord()\n",
    "        parameters = get_parameters(self.net)\n",
    "        \n",
    "        for i, param in enumerate(parameters):\n",
    "            p_record[f\"layer_{i}\"] = array_from_numpy(param)\n",
    "        \n",
    "        self.client_state.parameters_records[\"net_parameters\"] = p_record\n",
    "\n",
    "    def _load_model_state(self):\n",
    "        \"\"\"Load model parameters from context\"\"\"\n",
    "        p_record = self.client_state.parameters_records[\"net_parameters\"]\n",
    "        parameters = []\n",
    "        \n",
    "        for i in range(len(p_record)):\n",
    "            parameters.append(p_record[f\"layer_{i}\"].numpy())\n",
    "        \n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit\")\n",
    "\n",
    "        self._load_model_state()\n",
    "        recieved_parameter_size = get_parameters_size(ndarrays_to_parameters(parameters))  \n",
    "        set_parameters(self.net, parameters, config[\"updated_layers\"])\n",
    "        freeze_layers(self.net, config[\"trainable_layers\"])\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters())\n",
    "        if \"optimizer_state\" in config:\n",
    "            print(f\"Got optimizer state in config, setting..\")\n",
    "            serialized_optimizer_state = config[\"optimizer_state\"]\n",
    "            optim_state = deserialize_optimizer_state(serialized_optimizer_state)\n",
    "            self._set_optimizer_state(optim_state)\n",
    "\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS, optimizer=self.optimizer)\n",
    "        self._save_model_state()\n",
    "        print('finished train')\n",
    "\n",
    "        # handle optimizer state (serialize before passing)\n",
    "        optim_state = self._get_optimizer_state()\n",
    "        serialized_optimizer_state = serialize_optimizer_state(optim_state)\n",
    "        print(f\"After training, got optim state {serialized_optimizer_state[:50]}\")\n",
    "\n",
    "        new_config = {\n",
    "            \"trained_layer\":config[\"trainable_layers\"], \n",
    "            \"recieved_parameter_size\": recieved_parameter_size,\n",
    "            \"optimizer_state\": serialized_optimizer_state\n",
    "        }\n",
    "\n",
    "        return self.get_parameters(config), len(self.trainloader), new_config\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        self._load_model_state()\n",
    "        # This part looks a bit sus. Why are we loading and then setting params to be the same?\n",
    "        current_state = get_parameters(self.net)\n",
    "        set_parameters(self.net, current_state)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    def _get_optimizer_state(self):\n",
    "        \"\"\"Extract only the necessary parts of optimizer state\"\"\"\n",
    "        state_dict = self.optimizer.state_dict()\n",
    "        # Extract only essential information\n",
    "        pruned_state = {'state': {}, 'param_groups': state_dict['param_groups']}\n",
    "        \n",
    "        for k, v in state_dict['state'].items():\n",
    "            pruned_state['state'][k] = {\n",
    "                'exp_avg': v['exp_avg'].clone().detach().cpu(),\n",
    "                'exp_avg_sq': v['exp_avg_sq'].clone().detach().cpu(),\n",
    "                'step': v['step']\n",
    "            }\n",
    "        \n",
    "        return pruned_state\n",
    "\n",
    "    def _set_optimizer_state(self, state_dict):\n",
    "        \"\"\"Load optimizer state efficiently\"\"\"\n",
    "        # Move tensors to the appropriate device first\n",
    "        for k in state_dict['state']:\n",
    "            for key in ['exp_avg', 'exp_avg_sq']:\n",
    "                if key in state_dict['state'][k]:\n",
    "                    state_dict['state'][k][key] = state_dict['state'][k][key].to(DEVICE)\n",
    "        \n",
    "        self.optimizer.load_state_dict(state_dict)\n",
    "    \n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    # Initialize network if not in context\n",
    "    if not hasattr(context, 'net'):\n",
    "        context.net = Net().to(DEVICE)\n",
    "    \n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "\n",
    "    return FedAvgPartWithVelocityFlowerClient(partition_id, context.net, trainloader, valloader, context).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "client_manager = DropoutClientManager(dropout_rate=0.5)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedPartAvgWithVelocity(\n",
    "            evaluate_fn=evaluate_fn,\n",
    "        ),\n",
    "        client_manager=client_manager\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_part_avg_client_dropout_result.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_avg_result, file)\n",
    "\n",
    "with open(f'results/fed_part_avg_model_client_dropout_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_avg_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # Plot the total size of parameters for each round\n",
    "# fed_part_avg_rounds = list(fed_part_avg_result.keys())\n",
    "# fed_part_avg_sizes = [fed_part_avg_result[round][\"total_size\"] for round in fed_part_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='b', label='FedPartAvgMomentum')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_avg_losses = [fed_part_avg_result[round][\"total_loss\"] for round in fed_part_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='b', label='FedPartAvgMomentum')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_part_avg_model_rounds = list(fed_part_avg_model_results.keys())\n",
    "# fed_part_avg_accuracies = [fed_part_avg_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_part_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='b', label='FedPartAvgMomentum')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_avg_global_losses = [fed_part_avg_model_results[round][\"global_loss\"] for round in fed_part_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='b', label='FedPartAvgMomentum')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss for Each Round')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using momentum similarity for weighing updates\n",
    "Weigh updates by cosine similarity between client momentum and global momentum from previous round. \n",
    "\n",
    "Future work ideas:\n",
    "- Save cosine similarities. Use these to compute the distributions of these similarities and identify\n",
    "- Use cosine similarities to identify outlier clients.\n",
    "This is likely of greater interest in heterogeneous data settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from functools import partial, reduce\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "fed_momentum_weighting_results = {}\n",
    "fed_momentum_weighting_model_results = {}\n",
    "\n",
    "global client_opt\n",
    "global prev_opt\n",
    "\n",
    "class FedPartAvgWithVelocityweighting(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "\n",
    "        self.layer_update_strategy = layer_update_strategy  # 'sequential' or 'cyclic'\n",
    "        self.current_layer = 0  # Track which layer to update\n",
    "        self.number_of_layers = None\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "        self.updated_layers = -1\n",
    "        self.global_optim_state = None\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartAvgWithVelocityWeighting\"\n",
    "    \n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "    \n",
    "    def generate_layer_training_sequence(self) -> List[int]:\n",
    "        \"\"\"Generate a sequence of layers to train.\"\"\"\n",
    "        layer_training_sequence = []\n",
    "        for _ in range(NUM_OF_CYCLES):\n",
    "            for _ in range(NUM_OF_FULL_UPDATES_BETWEEN_CYCLES):\n",
    "                    layer_training_sequence.append(-1)\n",
    "            for layer in range(NETWORK_LEN):\n",
    "                    layer_training_sequence.append(layer)\n",
    "                    layer_training_sequence.append(layer)\n",
    "\n",
    "        return layer_training_sequence\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        self.layer_training_sequence = self.generate_layer_training_sequence()\n",
    "        self.number_of_layers = len(ndarrays)\n",
    "\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_momentum_weighting_model_results:  \n",
    "            expand_fed_part_avg_model_results= {**fed_momentum_weighting_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_part_avg_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_momentum_weighting_model_results[server_round] = expand_fed_part_avg_model_results\n",
    "        \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {\"trainable_layers\": self.layer_training_sequence[self.training_sequence_index], \"updated_layers\": self.updated_layers}\n",
    "\n",
    "        if self.global_optim_state is not None:\n",
    "            config[\"optimizer_state\"] = self.global_optim_state\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        print(f\"Training on layer {self.layer_training_sequence}\")\n",
    "        fit_configurations = []\n",
    "\n",
    "        params_array = parameters_to_ndarrays(parameters)\n",
    "        \n",
    "        # If doing full model update, send all parameters\n",
    "        if self.layer_training_sequence[self.training_sequence_index] == -1 or self.updated_layers == -1:\n",
    "            selected_params = parameters\n",
    "        else:\n",
    "            layer_idx = self.updated_layers\n",
    "            selected_params = ndarrays_to_parameters([\n",
    "                    params_array[layer_idx * 2],     # Weight\n",
    "                    params_array[layer_idx * 2 + 1]  # Bias\n",
    "                ])\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(selected_params, config)))\n",
    "\n",
    "        self.updated_layers = self.layer_training_sequence[self.training_sequence_index]\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        global global_all_optimizer_states\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters)\n",
    "            total_size += fit_res.metrics[\"recieved_parameter_size\"]\n",
    "            \n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        metrics = {}\n",
    "        optimizer_states_serialized = [res.metrics.get(\"optimizer_state\", None) for _, res in results]\n",
    "        optimizer_states = [deserialize_optimizer_state(state) for state in optimizer_states_serialized if state is not None]\n",
    "\n",
    "        # Get cosine similarities\n",
    "        if server_round == 1:\n",
    "            # First round doesn't have a previous state. Use average momentum instead\n",
    "            equal_weights = [1] * len(optimizer_states)\n",
    "            prev_global_optimizer_state = self._aggregate_optimizer_states_weighted(optimizer_states, equal_weights)\n",
    "        else:\n",
    "            prev_global_optimizer_state = deserialize_optimizer_state(self.global_optim_state)\n",
    "        cos_similarities = self._cos_similarity_from_optimizer_states(optimizer_states, prev_global_optimizer_state)\n",
    "\n",
    "        # Aggregate nn params using weighting from momentum\n",
    "        aggregated_weights = self._aggregate_params_weighted(weights_results, cos_similarities)\n",
    "        trained_layer = results[0][1].metrics[\"trained_layer\"] \n",
    "\n",
    "        if trained_layer == -1:\n",
    "            self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "        else:\n",
    "            current_model = parameters_to_ndarrays(self.latest_parameters)\n",
    "            current_model[trained_layer* 2] = aggregated_weights[0]\n",
    "            current_model[trained_layer* 2 +1] = aggregated_weights[1]\n",
    "            self.latest_parameters = ndarrays_to_parameters(current_model)\n",
    "\n",
    "        # aggregate optimizer state using weighting from momentum\n",
    "        aggregated_optimizer_state = self._aggregate_optimizer_states_weighted(optimizer_states, cos_similarities)\n",
    "        aggregated_optimizer_state_serialized = serialize_optimizer_state(aggregated_optimizer_state)\n",
    "        metrics[\"optimizer_state\"] = aggregated_optimizer_state_serialized\n",
    "        self.global_optim_state = aggregated_optimizer_state_serialized\n",
    "\n",
    "        # Add sizes to total_size:\n",
    "        # Note that we currently add the whole optimizer state for ease of implementation, but this is redundant for all but the unfrozen layer as the frozen layers opt state is unchanged.\n",
    "        sizes = sum([sys.getsizeof(data) for data in optimizer_states_serialized if data is not None])\n",
    "        print(f\"Adding optimizer state adds size {sizes}\")\n",
    "        total_size += sizes\n",
    "\n",
    "        if fed_momentum_weighting_results.get(server_round):\n",
    "            fed_momentum_weighting_results[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_momentum_weighting_results[server_round] = {\"total_size\": total_size}\n",
    "\n",
    "        return self.latest_parameters, metrics\n",
    "\n",
    "\n",
    "    def _momentum_based_aggregate(results: list[tuple[NDArrays, int]]) -> NDArrays:\n",
    "        \"\"\"Compute weighted average of params.\"\"\"\n",
    "        num_examples_total = sum(num_examples for (_, num_examples) in results)\n",
    "\n",
    "        # list of weights, each multiplied by the related number of examples\n",
    "        weighted_weights = [\n",
    "            [layer * num_examples for layer in weights] for weights, num_examples in results\n",
    "        ]\n",
    "\n",
    "        # Compute average weights of each layer\n",
    "        weights_prime: NDArrays = [\n",
    "            reduce(np.add, layer_updates) / num_examples_total\n",
    "            for layer_updates in zip(*weighted_weights)\n",
    "        ]\n",
    "        return weights_prime\n",
    "\n",
    "    def _aggregate_optimizer_states_weighted(self, optimizer_states, similarities):\n",
    "        # aggregates by comuting mean of 1st and 2nd momentum, and taking the maximum step value. (alternatively, could be changed to reset steps to 0)\n",
    "        # uses direct normalization (weight of similarity divided by sum of similarities)\n",
    "        aggregated_state_dict = copy.deepcopy(optimizer_states[0])\n",
    "        sum_similarities = sum(similarities)\n",
    "\n",
    "        for layer in range(len(optimizer_states[0]['state'])):\n",
    "            weighted_fst_momentum = torch.zeros_like(optimizer_states[0]['state'][layer]['exp_avg'])\n",
    "            weighted_snd_momentum = torch.zeros_like(optimizer_states[0]['state'][layer]['exp_avg_sq'])\n",
    "            \n",
    "            # Accumulate weighted momentums from each client\n",
    "            for i in range(len(optimizer_states)):\n",
    "                weight = similarities[i] / sum_similarities\n",
    "                weighted_fst_momentum += optimizer_states[i]['state'][layer]['exp_avg'] * weight\n",
    "                weighted_snd_momentum += optimizer_states[i]['state'][layer]['exp_avg_sq'] * weight\n",
    "\n",
    "            aggregated_state_dict['state'][layer]['exp_avg'] = weighted_fst_momentum\n",
    "            aggregated_state_dict['state'][layer]['exp_avg_sq'] = weighted_snd_momentum\n",
    "        max_steps = max([optimizer_states[i]['state'][layer]['step'] for i in range(len(optimizer_states))])\n",
    "        aggregated_state_dict['state'][layer]['step'] = max_steps\n",
    "        \n",
    "        return aggregated_state_dict\n",
    "\n",
    "    def _aggregate_params_weighted(self, results: list[tuple[NDArrays, int]], cos_similarities: list[float]) -> NDArrays:\n",
    "        \"\"\"Compute cos similarity weighted average.\"\"\"\n",
    "        # Calculate the total number of examples used during training\n",
    "        assert len(results) == len(cos_similarities)\n",
    "        sum_sim = sum(cos_similarities)\n",
    "\n",
    "        # Create a list of weights, each multiplied by the cos similiarity\n",
    "        weighted_weights = [\n",
    "            [layer * cos_similarities[i] for layer in results[i][0]] for i in range(len(results))\n",
    "        ]\n",
    "\n",
    "        # Compute average weights of each layer\n",
    "        weights_prime: NDArrays = [\n",
    "            reduce(np.add, layer_updates) / sum_sim\n",
    "            for layer_updates in zip(*weighted_weights)\n",
    "        ]\n",
    "        return weights_prime\n",
    "\n",
    "    def _cos_similarity_from_optimizer_states(self, optimizer_states, prev_global_optimizer_state):\n",
    "        # Returns: cosine similarity from each optimizer state to the prev global state\n",
    "        cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "        similarities = []\n",
    "        layers = range(len(optimizer_states[0]['state']))\n",
    "\n",
    "        # get global opt params as vector\n",
    "        fst_momentum_glob = [prev_global_optimizer_state['state'][l]['exp_avg'].view(-1) for l in layers]\n",
    "        snd_momentum_glob = [prev_global_optimizer_state['state'][l]['exp_avg_sq'].view(-1) for l in layers]\n",
    "        glob_state_vec = torch.cat(fst_momentum_glob + snd_momentum_glob)\n",
    "\n",
    "        for client in range(len(optimizer_states)):\n",
    "            # get client opt params as vector\n",
    "            fst_momentum_client = [optimizer_states[client]['state'][l]['exp_avg'].view(-1) for l in layers]\n",
    "            snd_momentum_client = [optimizer_states[client]['state'][l]['exp_avg_sq'].view(-1) for l in layers]\n",
    "            client_state_vec = torch.cat(fst_momentum_client + snd_momentum_client)\n",
    "\n",
    "            sim = cos(client_state_vec, glob_state_vec)\n",
    "            similarities.append(sim.item())\n",
    "\n",
    "        return similarities\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_momentum_weighting_results.get(server_round):\n",
    "            fed_momentum_weighting_results[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_momentum_weighting_results[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgPartWithVelocityWeightingFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, context: Context):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.client_state = context.state\n",
    "\n",
    "        # Initialize parameters record if it doesn't exist\n",
    "        if \"net_parameters\" not in self.client_state.parameters_records:\n",
    "            self.client_state.parameters_records[\"net_parameters\"] = ParametersRecord()\n",
    "            # Save initial model state\n",
    "            self._save_model_state()\n",
    "\n",
    "    def _save_model_state(self):\n",
    "        \"\"\"Save current model parameters to context\"\"\"\n",
    "        p_record = ParametersRecord()\n",
    "        parameters = get_parameters(self.net)\n",
    "        \n",
    "        for i, param in enumerate(parameters):\n",
    "            p_record[f\"layer_{i}\"] = array_from_numpy(param)\n",
    "        \n",
    "        self.client_state.parameters_records[\"net_parameters\"] = p_record\n",
    "\n",
    "    def _load_model_state(self):\n",
    "        \"\"\"Load model parameters from context\"\"\"\n",
    "        p_record = self.client_state.parameters_records[\"net_parameters\"]\n",
    "        parameters = []\n",
    "        \n",
    "        for i in range(len(p_record)):\n",
    "            parameters.append(p_record[f\"layer_{i}\"].numpy())\n",
    "        \n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        trainable_layer = config[\"trainable_layers\"]\n",
    "        self._save_model_state()\n",
    "        \n",
    "        if trainable_layer == -1:\n",
    "            return parameters\n",
    "        \n",
    "        trained_layer = [parameters[trainable_layer*2], parameters[trainable_layer*2 +1]]\n",
    "        return trained_layer\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit\")\n",
    "\n",
    "        self._load_model_state()\n",
    "        received_parameter_size = get_parameters_size(ndarrays_to_parameters(parameters))\n",
    "        set_parameters(self.net, parameters, config[\"updated_layers\"])\n",
    "        freeze_layers(self.net, config[\"trainable_layers\"])\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters())\n",
    "        if \"optimizer_state\" in config:\n",
    "            print(f\"Got optimizer state in config, setting..\")\n",
    "            serialized_optimizer_state = config[\"optimizer_state\"]\n",
    "            optim_state = deserialize_optimizer_state(serialized_optimizer_state)\n",
    "            self._set_optimizer_state(optim_state)\n",
    "\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS, optimizer=self.optimizer)\n",
    "        print('finished train')\n",
    "\n",
    "        # handle optimizer state (serialize before passing)\n",
    "        optim_state = self._get_optimizer_state()\n",
    "        serialized_optimizer_state = serialize_optimizer_state(optim_state)\n",
    "        print(f\"After training, got optim state {serialized_optimizer_state[:50]}\")\n",
    "\n",
    "        new_config =  {\n",
    "            \"trained_layer\":config[\"trainable_layers\"], \n",
    "            \"recieved_parameter_size\": received_parameter_size,\n",
    "            \"optimizer_state\": serialized_optimizer_state\n",
    "            }\n",
    "\n",
    "        self._save_model_state()\n",
    "\n",
    "        return self.get_parameters(config), len(self.trainloader), new_config\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        self._load_model_state()\n",
    "        current_state = get_parameters(self.net)\n",
    "        set_parameters(self.net, current_state)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    \n",
    "    def _get_optimizer_state(self):\n",
    "        state_dict = self.optimizer.state_dict()\n",
    "        return state_dict\n",
    "    \n",
    "    def _set_optimizer_state(self, state_dict):\n",
    "        self.optimizer.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    # Initialize network if not in context\n",
    "    if not hasattr(context, 'net'):\n",
    "        context.net = Net().to(DEVICE)\n",
    "\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedAvgPartWithVelocityWeightingFlowerClient(partition_id, context.net, trainloader, valloader, context).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "client_manager = DropoutClientManager(dropout_rate=0.5)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedPartAvgWithVelocityweighting(\n",
    "            evaluate_fn=evaluate_fn,\n",
    "        ),\n",
    "        client_manager=client_manager\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_momentum_weighting_client_dropout_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_momentum_weighting_results, file)\n",
    "\n",
    "with open(f'results/fed_momentum_weighting_model_client_dropout_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_momentum_weighting_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot the total size of parameters for each round\n",
    "# fed_momentum_weighting_rounds = list(fed_momentum_weighting_results.keys())\n",
    "# fed_momentum_weighting_sizes = [fed_momentum_weighting_results[round][\"total_size\"] for round in fed_momentum_weighting_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_momentum_weighting_rounds, fed_momentum_weighting_sizes, marker='o', linestyle='-', color='b', label='FedPartWithVelocityWeighting')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_momentum_weighting_losses = [fed_momentum_weighting_results[round][\"total_loss\"] for round in fed_momentum_weighting_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_momentum_weighting_rounds, fed_momentum_weighting_losses, marker='o', linestyle='-', color='b', label='FedPartWithVelocityWeighting')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_momentum_weighting_model_rounds = list(fed_momentum_weighting_model_results.keys())\n",
    "# fed_momentum_weighting_accuracies = [fed_momentum_weighting_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_momentum_weighting_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_momentum_weighting_model_rounds, fed_momentum_weighting_accuracies, marker='o', linestyle='-', color='b', label='FedPartWithVelocityWeighting')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_momentum_weighting_global_losses = [fed_momentum_weighting_model_results[round][\"global_loss\"] for round in fed_momentum_weighting_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_momentum_weighting_model_rounds, fed_momentum_weighting_global_losses, marker='o', linestyle='-', color='b', label='FedPartWithVelocityWeighting')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss for Each Round')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
