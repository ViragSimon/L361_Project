{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: urllib3==1.26.6 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib\n",
    "! pip install -U ipywidgets\n",
    "! pip install numpy==1.26.4\n",
    "! pip install urllib3==1.26.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.15.2 / PyTorch 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple, Union, Callable\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr.server.strategy import Strategy\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context, Status, GetParametersRes, Parameters, GetParametersIns, MetricsAggregationFn,NDArrays,Scalar\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents \n",
    "from flwr.server.strategy import FedAvg, FedProx\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    "    ParametersRecord,\n",
    "    array_from_numpy\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = \"mps\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    drichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=0.1, partition_by=\"label\")\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": drichlet_partitioner})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        \n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MoonNet(nn.Module):\n",
    "    \"\"\"Returns both the representation (penultimate layer output) and classification\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(MoonNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        representation = x.clone()\n",
    "        classification = self.fc3(x)\n",
    "        return representation, classification\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters, trainable_layers=-1):\n",
    "    \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n",
    "    current_state = OrderedDict(net.state_dict())\n",
    "    \n",
    "    if trainable_layers == -1:\n",
    "        # Update all parameters\n",
    "        params_dict = zip(current_state.keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "    else:\n",
    "        # Only update the specified layer's parameters\n",
    "        # Convert current state to numpy arrays\n",
    "        numpy_state = [param.cpu().numpy() for param in current_state.values()]\n",
    "        \n",
    "        # Update the specific indices with new parameters\n",
    "        numpy_state[trainable_layers*2] = parameters[0]\n",
    "        numpy_state[trainable_layers*2 + 1] = parameters[1]\n",
    "        \n",
    "        # Convert back to torch and update state dict\n",
    "        for idx, key in enumerate(current_state.keys()):\n",
    "            current_state[key] = torch.from_numpy(numpy_state[idx])\n",
    "        \n",
    "        net.load_state_dict(current_state, strict=True)\n",
    "\n",
    "\n",
    "# def set_parameters(net, parameters: List[np.ndarray]):\n",
    "#     params_dict = zip(net.state_dict().keys(), parameters)\n",
    "#     state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "#     net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "        \n",
    "def proxima_train(net, trainloader, epochs: int, proximal_mu:float, global_params:List[torch.Tensor]):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "\n",
    "            proximal_term = 0.0\n",
    "            for local_weights, global_weights in zip(net.parameters(), global_params):\n",
    "                proximal_term += (local_weights - global_weights).norm(2)\n",
    "            loss = criterion(net(images), labels) + (proximal_mu / 2) * proximal_term\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def train_moon(net,train_loader, global_net,previous_net, epochs, mu, temperature):\n",
    "    \"\"\"Training function for MOON.\"\"\"\n",
    "    print(f\"Started training moon\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    previous_net.eval()\n",
    "    global_net.eval()\n",
    "    net.to(DEVICE)\n",
    "    previous_net.to(DEVICE)\n",
    "    global_net.to(DEVICE)\n",
    "    cnt = 0\n",
    "    cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_collector = []\n",
    "        epoch_loss1_collector = []\n",
    "        epoch_loss2_collector = []\n",
    "        for batch in train_loader:\n",
    "            x, target = batch[\"img\"], batch[\"label\"]\n",
    "            x, target = x.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # pro1 is the representation by the current model (Line 14 of Algorithm 1)\n",
    "            pro1, out = net(x)\n",
    "            # pro2 is the representation by the global model (Line 15 of Algorithm 1)\n",
    "            # pro3 is the representation by the previous model (Line 16 of Algorithm 1)\n",
    "            with torch.no_grad():\n",
    "                pro2, _ = global_net(x)\n",
    "                pro3, _ = previous_net(x)\n",
    "\n",
    "            # posi is the positive pair\n",
    "            posi = cos(pro1, pro2)\n",
    "            logits = posi.reshape(-1, 1)\n",
    "\n",
    "            # nega is the negative pair\n",
    "            nega = cos(pro1, pro3)\n",
    "            logits = torch.cat((logits, nega.reshape(-1, 1)), dim=1)\n",
    "\n",
    "            previous_net.to(DEVICE)\n",
    "            logits /= temperature\n",
    "            labels = torch.zeros(x.size(0)).to(DEVICE).long()\n",
    "\n",
    "            # compute the model-contrastive loss (Line 17 of Algorithm 1)\n",
    "            loss2 = mu * criterion(logits, labels)\n",
    "\n",
    "            # compute the cross-entropy loss (Line 13 of Algorithm 1)\n",
    "            loss1 = criterion(out, target)\n",
    "\n",
    "            # compute the loss (Line 18 of Algorithm 1)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cnt += 1\n",
    "            epoch_loss_collector.append(loss.item())\n",
    "            epoch_loss1_collector.append(loss1.item())\n",
    "            epoch_loss2_collector.append(loss2.item())\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
    "        epoch_loss1 = sum(epoch_loss1_collector) / len(epoch_loss1_collector)\n",
    "        epoch_loss2 = sum(epoch_loss2_collector) / len(epoch_loss2_collector)\n",
    "        print(\n",
    "            \"Epoch: %d Loss: %f Loss1: %f Loss2: %f\"\n",
    "            % (epoch, epoch_loss, epoch_loss1, epoch_loss2)\n",
    "        )\n",
    "\n",
    "\n",
    "def test_moon(net, testloader):\n",
    "    \"\"\"\n",
    "    Evaluate the network on the entire test set.\n",
    "    Same as the regular test, but using the MoonNet \n",
    "    (where the output is a tuple of (representation, classification) )\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            _, outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "# def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "#         \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "#         for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "#             if idx == trainable_layers or trainable_layers == -1:\n",
    "#                 param.requires_grad = True\n",
    "#             else:\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "        \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "        trainable_layers_set = []\n",
    "        if trainable_layers == -1:\n",
    "            trainable_layers_set = [-1]\n",
    "        else:\n",
    "            trainable_layers_set = [trainable_layers *2, trainable_layers *2 +1]\n",
    "\n",
    "        for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "            \n",
    "            if idx in trainable_layers_set or trainable_layers_set[0] == -1:\n",
    "                param.requires_grad = True\n",
    "                print(f\"layer index is {idx} and name{name} is trainabe\")\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                print(f\"layer index is {idx} and name{name} is frozen\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rounds: 23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NETWORK_LEN = len(Net().state_dict().keys()) //2 \n",
    "EPOCHS = 8\n",
    "NUM_PARTITIONS = 6\n",
    "NUM_OF_CYCLES  = 1\n",
    "NUM_OF_FULL_UPDATES_BETWEEN_CYCLES = 5\n",
    "NUM_OF_ROUNDS = (NUM_OF_CYCLES * NUM_OF_FULL_UPDATES_BETWEEN_CYCLES) + (NUM_OF_CYCLES * NETWORK_LEN *2)\n",
    "print(f\"Number of rounds: {NUM_OF_ROUNDS}\")\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays, Scalar\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_evaluate_fn(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    \n",
    "    # used to check if they're changing\n",
    "    previous_params = None\n",
    "    \n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        nonlocal previous_params\n",
    "        \n",
    "        print(f\"\\n==== Server-side evaluation for round {server_round} ====\")\n",
    "        \n",
    "        # Check if parameters changed from previous round\n",
    "        if previous_params is not None:\n",
    "            param_change = False\n",
    "            for i, (prev, curr) in enumerate(zip(previous_params, parameters)):\n",
    "                diff = np.abs(prev - curr).mean()\n",
    "                if diff > 1e-6:\n",
    "                    param_change = True\n",
    "                    print(f\"  Parameter {i}: Changed by {diff:.6f}\")\n",
    "            \n",
    "            if not param_change:\n",
    "                print(\"  WARNING: Parameters haven't changed from previous round!\")\n",
    "        \n",
    "        previous_params = [p.copy() for p in parameters]\n",
    "        net_copy = copy.deepcopy(net)\n",
    "\n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v, device=DEVICE) for k, v in params_dict})\n",
    "        \n",
    "        # Check if state dict keys match model keys\n",
    "        model_keys = set(net_copy.state_dict().keys())\n",
    "        params_keys = set(state_dict.keys())\n",
    "        if model_keys != params_keys:\n",
    "            print(f\"  WARNING: Key mismatch between model and parameters!\")\n",
    "            print(f\"  Missing in params: {model_keys - params_keys}\")\n",
    "            print(f\"  Extra in params: {params_keys - model_keys}\")\n",
    "        \n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "        \n",
    "        # Test the model\n",
    "        loss, accuracy = test(net_copy, testloader)\n",
    "        print(f\"  Evaluation results - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    \n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_evaluate_fn_moon(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test_moon(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvgPart Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "fed_part_avg_result = {}\n",
    "\n",
    "fed_part_avg_model_results = {}\n",
    "\n",
    "\n",
    "class FedPartAvg(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "\n",
    "        self.layer_update_strategy = layer_update_strategy  # 'sequential' or 'cyclic'\n",
    "        self.current_layer = 0  # Track which layer to update\n",
    "        self.number_of_layers = None\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "        self.updated_layers = -1\n",
    "       \n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartAvg\"\n",
    "    \n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "    \n",
    "    def generate_layer_training_sequence(self) -> List[int]:\n",
    "        \"\"\"Generate a sequence of layers to train.\"\"\"\n",
    "        layer_training_sequence = []\n",
    "        for _ in range(NUM_OF_CYCLES):\n",
    "            for _ in range(NUM_OF_FULL_UPDATES_BETWEEN_CYCLES):\n",
    "                    layer_training_sequence.append(-1)\n",
    "            for layer in range(NETWORK_LEN):\n",
    "                    layer_training_sequence.append(layer)\n",
    "                    layer_training_sequence.append(layer)\n",
    "\n",
    "        return layer_training_sequence\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        self.layer_training_sequence = self.generate_layer_training_sequence()\n",
    "        self.number_of_layers = len(ndarrays)\n",
    "\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_part_avg_model_results:  \n",
    "            expand_fed_part_avg_model_results= {**fed_part_avg_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_part_avg_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_part_avg_model_results[server_round] = expand_fed_part_avg_model_results\n",
    "    \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {\"trainable_layers\": self.layer_training_sequence[self.training_sequence_index], \"updated_layers\": self.updated_layers}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        print(f\"Training on layer {self.layer_training_sequence}\")\n",
    "        fit_configurations = []\n",
    "\n",
    "        params_array = parameters_to_ndarrays(parameters)\n",
    "        \n",
    "        # If doing full model update, send all parameters\n",
    "        if self.layer_training_sequence[self.training_sequence_index] == -1 or self.updated_layers == -1:\n",
    "            selected_params = parameters\n",
    "        else:\n",
    "            layer_idx = self.updated_layers\n",
    "            selected_params = ndarrays_to_parameters([\n",
    "                    params_array[layer_idx * 2],     # Weight\n",
    "                    params_array[layer_idx * 2 + 1]  # Bias\n",
    "                ])\n",
    "\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(selected_params, config)))\n",
    "\n",
    "        self.updated_layers = self.layer_training_sequence[self.training_sequence_index]\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters)\n",
    "            total_size += fit_res.metrics[\"recieved_parameter_size\"]\n",
    "            \n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        if fed_part_avg_result.get(server_round):\n",
    "            fed_part_avg_result[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_part_avg_result[server_round] = {\"total_size\": total_size}\n",
    "        \n",
    "\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        \n",
    "\n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        # parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        trained_layer = results[0][1].metrics[\"trained_layer\"]\n",
    "        print(f\"aggregated weight size {len(aggregated_weights)} \")\n",
    "\n",
    "        if trained_layer == -1:\n",
    "            self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "        else:\n",
    "            current_model = parameters_to_ndarrays(self.latest_parameters)\n",
    "            print(f\"updateing layers {trained_layer* 2}  and {trained_layer* 2 + 1} \")\n",
    "            current_model[trained_layer* 2] = aggregated_weights[0]\n",
    "            current_model[trained_layer* 2 +1] = aggregated_weights[1]\n",
    "            self.latest_parameters = ndarrays_to_parameters(current_model)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        return self.latest_parameters, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_part_avg_result.get(server_round):\n",
    "            fed_part_avg_result[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_part_avg_result[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FedAvgPartFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, context: Context):\n",
    "        print(f\"[Client {partition_id}] initialized\")\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.client_state = context.state\n",
    "\n",
    "        # Initialize parameters record if it doesn't exist\n",
    "        if \"net_parameters\" not in self.client_state.parameters_records:\n",
    "            self.client_state.parameters_records[\"net_parameters\"] = ParametersRecord()\n",
    "            # Save initial model state\n",
    "            self._save_model_state()\n",
    "\n",
    "    def _save_model_state(self):\n",
    "        \"\"\"Save current model parameters to context\"\"\"\n",
    "        p_record = ParametersRecord()\n",
    "        parameters = get_parameters(self.net)\n",
    "        \n",
    "        for i, param in enumerate(parameters):\n",
    "            p_record[f\"layer_{i}\"] = array_from_numpy(param)\n",
    "        \n",
    "        self.client_state.parameters_records[\"net_parameters\"] = p_record\n",
    "\n",
    "    def _load_model_state(self):\n",
    "        \"\"\"Load model parameters from context\"\"\"\n",
    "        p_record = self.client_state.parameters_records[\"net_parameters\"]\n",
    "        parameters = []\n",
    "        \n",
    "        for i in range(len(p_record)):\n",
    "            parameters.append(p_record[f\"layer_{i}\"].numpy())\n",
    "        \n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        trainable_layer = config[\"trainable_layers\"]\n",
    "        self._save_model_state()\n",
    "        \n",
    "        if trainable_layer == -1:\n",
    "            return parameters\n",
    "        \n",
    "        trained_layer = [parameters[trainable_layer*2], parameters[trainable_layer*2 +1]]\n",
    "        return trained_layer\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        \n",
    "        self._load_model_state()\n",
    "        recieved_parameter_size = get_parameters_size(ndarrays_to_parameters(parameters))  \n",
    "        set_parameters(self.net, parameters, config[\"updated_layers\"])\n",
    "        freeze_layers(self.net, config[\"trainable_layers\"])\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS)\n",
    "        \n",
    "        self._save_model_state()\n",
    "        \n",
    "        return self.get_parameters(config), len(self.trainloader), {\"trained_layer\":config[\"trainable_layers\"], \"recieved_parameter_size\": recieved_parameter_size}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate\")\n",
    "        self._load_model_state()\n",
    "        current_state = get_parameters(self.net)\n",
    "        set_parameters(self.net, current_state)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    \n",
    "    # Initialize network if not in context\n",
    "    if not hasattr(context, 'net'):\n",
    "        context.net = Net().to(DEVICE)\n",
    "    \n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    \n",
    "    return FedAvgPartFlowerClient(\n",
    "        partition_id=partition_id,\n",
    "        net=context.net,\n",
    "        trainloader=trainloader,\n",
    "        valloader=valloader,\n",
    "        context=context\n",
    "    ).to_client()\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedPartAvg(\n",
    "            evaluate_fn=evaluate_fn,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_part_avg_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_avg_result, file)\n",
    "\n",
    "with open(f'results/fed_part_avg_model_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_avg_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# # Plot the total size of parameters for each round\n",
    "# fed_part_avg_rounds = list(fed_part_avg_result.keys())\n",
    "# fed_part_avg_sizes = [fed_part_avg_result[round][\"total_size\"] for round in fed_part_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='b', label='FedPartAvg')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_avg_losses = [fed_part_avg_result[round][\"total_loss\"] for round in fed_part_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='b', label='FedPartAvg')\n",
    "# # plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_part_avg_model_rounds = list(fed_part_avg_model_results.keys())\n",
    "# fed_part_avg_accuracies = [fed_part_avg_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_part_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='b', label='FedPartAvg')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_avg_global_losses = [fed_part_avg_model_results[round][\"global_loss\"] for round in fed_part_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='b', label='FedPartAvg')\n",
    "# # plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='r', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.title('Loss for Each Round')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedProxPart Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProxPartFlowerClient(FedAvgPartFlowerClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, context: Context):\n",
    "        super().__init__(partition_id, net, trainloader, valloader, context)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config} with parameters size {parameters}\")\n",
    "        self._load_model_state()\n",
    "        \n",
    "        recieved_parameter_size = get_parameters_size(ndarrays_to_parameters(parameters))     \n",
    "        # recieved_parameter_size = 1  \n",
    "        set_parameters(self.net, parameters, config[\"updated_layers\"])\n",
    "        global_params = copy.deepcopy(self.net).parameters()\n",
    "        freeze_layers(self.net, config[\"trainable_layers\"])\n",
    "        proxima_train(self.net, self.trainloader, EPOCHS, config[\"proximal_mu\"], global_params)\n",
    "        self._save_model_state()\n",
    "        return self.get_parameters(config), len(self.trainloader), {\"trained_layer\":config[\"trainable_layers\"], \"recieved_parameter_size\": recieved_parameter_size}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    if not hasattr(context, \"net\"): \n",
    "        context.net = Net().to(DEVICE)\n",
    "\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedProxPartFlowerClient(partition_id, context.net, trainloader, valloader, context).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_part_prox_result = {}\n",
    "\n",
    "fed_part_prox_model_results = {}\n",
    "\n",
    "class FedPartProx(FedPartAvg):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        proximal_mu: float,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_evaluate=fraction_evaluate,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_evaluate_clients=min_evaluate_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            evaluate_fn=evaluate_fn,\n",
    "            on_fit_config_fn=on_fit_config_fn,\n",
    "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "            accept_failures=accept_failures,\n",
    "            initial_parameters=initial_parameters,\n",
    "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        )\n",
    "        self.proximal_mu = proximal_mu\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartProx\"\n",
    "    \n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> list[tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\n",
    "\n",
    "        Sends the proximal factor mu to the clients\n",
    "        \"\"\"\n",
    "        # Get the standard client/config pairs from the FedAvg super-class\n",
    "        client_config_pairs = super().configure_fit(\n",
    "            server_round, parameters, client_manager\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs with the proximal factor mu added\n",
    "        return [\n",
    "            (\n",
    "                client,\n",
    "                FitIns(\n",
    "                    fit_ins.parameters,\n",
    "                    {**fit_ins.config, \"proximal_mu\": self.proximal_mu},\n",
    "                ),\n",
    "            )\n",
    "            for client, fit_ins in client_config_pairs\n",
    "        ]\n",
    "    \n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters)\n",
    "            total_size += fit_res.metrics[\"recieved_parameter_size\"]\n",
    "\n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        if fed_part_prox_result.get(server_round):\n",
    "            fed_part_prox_result[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_part_prox_result[server_round] = {\"total_size\": total_size}\n",
    "        \n",
    "\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        # parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        trained_layer = results[0][1].metrics[\"trained_layer\"]\n",
    "        print(f\"aggregated weight size {len(aggregated_weights)} \")\n",
    "\n",
    "        if self.layer_training_sequence[self.training_sequence_index -1] == -1:\n",
    "            self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "        else:\n",
    "            current_model = parameters_to_ndarrays(self.latest_parameters)\n",
    "            print(f\"updateing layers {self.layer_training_sequence[self.training_sequence_index -1]* 2}  and {self.layer_training_sequence[self.training_sequence_index -1]* 2 + 1} \")\n",
    "            current_model[self.layer_training_sequence[self.training_sequence_index -1]* 2] = aggregated_weights[0]\n",
    "            current_model[self.layer_training_sequence[self.training_sequence_index -1]* 2 +1] = aggregated_weights[1]\n",
    "            self.latest_parameters = ndarrays_to_parameters(current_model)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        return self.latest_parameters, metrics_aggregated\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_part_prox_result.get(server_round):\n",
    "            fed_part_prox_result[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_part_prox_result[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "    \n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_part_prox_model_results:  \n",
    "            expand_fed_part_prox_model_results= {**fed_part_prox_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_part_prox_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_part_prox_model_results[server_round] = expand_fed_part_prox_model_results\n",
    "        \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedPartProx(proximal_mu=0.1, evaluate_fn=evaluate_fn),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_part_prox_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_prox_result, file)\n",
    "\n",
    "with open(f'results/fed_part_prox_model_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_part_prox_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_part_prox_rounds = list(fed_part_prox_result.keys())\n",
    "fed_part_prox_sizes = [fed_part_prox_result[round][\"total_size\"] for round in fed_part_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_sizes, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_prox_losses = [fed_part_prox_result[round][\"total_loss\"] for round in fed_part_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_losses, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_part_prox_model_rounds = list(fed_part_prox_model_results.keys())\n",
    "# fed_part_prox_accuracies = [fed_part_prox_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_part_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_accuracies, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_prox_global_losses = [fed_part_prox_model_results[round][\"global_loss\"] for round in fed_part_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_global_losses, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')   \n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedPartMoon Experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import sys\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n",
    "\n",
    "fed_moon_result = {}\n",
    "fed_moon_model_results = {}\n",
    "\n",
    "# basically same as normal FedAvg, just added freezing and modified result dict names\n",
    "class FedMoon(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "        self.updated_layers = -1\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartMoon\"\n",
    "    \n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "   \n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        self.layer_training_sequence = self.generate_layer_training_sequence()\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def generate_layer_training_sequence(self) -> List[int]:\n",
    "        \"\"\"Generate a sequence of layers to train.\"\"\"\n",
    "        layer_training_sequence = []\n",
    "        for _ in range(NUM_OF_CYCLES):\n",
    "            for _ in range(NUM_OF_FULL_UPDATES_BETWEEN_CYCLES):\n",
    "                    layer_training_sequence.append(-1)\n",
    "            for layer in range(NETWORK_LEN):\n",
    "                    layer_training_sequence.append(layer)\n",
    "                    layer_training_sequence.append(layer)\n",
    "\n",
    "        return layer_training_sequence\n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "\n",
    "        if server_round in fed_moon_model_results:\n",
    "            expand_fed_moon_result= {**fed_moon_model_results[server_round], \"global_loss\": loss, \"global_metrics\": metrics}\n",
    "        else:\n",
    "            expand_fed_moon_result= {\"global_loss\": loss, \"global_metrics\": metrics}\n",
    "\n",
    "        fed_moon_model_results[server_round] = expand_fed_moon_result\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "    def configure_fit(\n",
    "        # includes layer freezing\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {\"trainable_layers\": self.layer_training_sequence[self.training_sequence_index],\"updated_layers\": self.updated_layers}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        print(f\"sample size {sample_size} and min num clients {min_num_clients}\")\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        fit_configurations = []\n",
    "\n",
    "        params_array = parameters_to_ndarrays(parameters)\n",
    "        \n",
    "        # If doing full model update, send all parameters\n",
    "        if self.layer_training_sequence[self.training_sequence_index] == -1 or self.updated_layers == -1:\n",
    "            selected_params = parameters\n",
    "        else:\n",
    "            layer_idx = self.updated_layers\n",
    "            selected_params = ndarrays_to_parameters([\n",
    "                    params_array[layer_idx * 2],     # Weight\n",
    "                    params_array[layer_idx * 2 + 1]  # Bias\n",
    "                ])\n",
    "\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(selected_params, config)))\n",
    "\n",
    "        self.updated_layers = self.layer_training_sequence[self.training_sequence_index]\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "\n",
    "        return fit_configurations\n",
    "\n",
    "        \n",
    "    \n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # get size of parameters in bytes\n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters)\n",
    "            total_size += fit_res.metrics[\"recieved_parameter_size\"]\n",
    "        \n",
    "        if server_round in fed_moon_result:\n",
    "            expand_fed_moon_result= {**fed_moon_result[server_round], \"total_size\": total_size}\n",
    "        else:\n",
    "            expand_fed_moon_result= {\"total_size\": total_size}\n",
    "\n",
    "        fed_moon_result[server_round] = expand_fed_moon_result\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        \n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        \n",
    "        trained_layer = results[0][1].metrics[\"trained_layer\"]\n",
    "        print(f\"aggregated weight size {len(aggregated_weights)} \")\n",
    "\n",
    "        if trained_layer == -1:\n",
    "            self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "        else:\n",
    "            current_model = parameters_to_ndarrays(self.latest_parameters)\n",
    "            print(f\"updateing layers {trained_layer* 2}  and {trained_layer* 2 + 1} \")\n",
    "            current_model[trained_layer* 2] = aggregated_weights[0]\n",
    "            current_model[trained_layer* 2 +1] = aggregated_weights[1]\n",
    "            self.latest_parameters = ndarrays_to_parameters(current_model)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        return self.latest_parameters, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss \n",
    "\n",
    "\n",
    "        if server_round in fed_moon_result:\n",
    "            expand_fed_moon_result= {**fed_moon_result[server_round], \"total_loss\": total_loss}\n",
    "        else:\n",
    "            expand_fed_moon_result= {\"total_loss\": total_loss}\n",
    "\n",
    "        fed_moon_result[server_round] = expand_fed_moon_result\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class FedMoonPartFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader, context: Context):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model_dir = \"models\"\n",
    "        self.client_state = context.state\n",
    "\n",
    "        if \"net_parameters\" not in self.client_state.parameters_records:\n",
    "            self.client_state.parameters_records[\"net_parameters\"] = ParametersRecord()\n",
    "            # Save initial model state\n",
    "            self._save_model_state()\n",
    "\n",
    "\n",
    "\n",
    "    def _save_model_state(self):\n",
    "        \"\"\"Save current model parameters to context\"\"\"\n",
    "        p_record = ParametersRecord()\n",
    "        parameters = get_parameters(self.net)\n",
    "        \n",
    "        for i, param in enumerate(parameters):\n",
    "            p_record[f\"layer_{i}\"] = array_from_numpy(param)\n",
    "        \n",
    "        self.client_state.parameters_records[\"net_parameters\"] = p_record\n",
    "\n",
    "    def _load_model_state(self):\n",
    "        \"\"\"Load model parameters from context\"\"\"\n",
    "        p_record = self.client_state.parameters_records[\"net_parameters\"]\n",
    "        parameters = []\n",
    "        \n",
    "        for i in range(len(p_record)):\n",
    "            parameters.append(p_record[f\"layer_{i}\"].numpy())\n",
    "        \n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        if config[\"trainable_layers\"] == -1:\n",
    "            return parameters\n",
    "        \n",
    "        trained_layer = [parameters[config[\"trainable_layers\"]*2], parameters[config[\"trainable_layers\"]*2 +1]]\n",
    "        return trained_layer\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "\n",
    "        # update params for current model (loading global params)\n",
    "        self._load_model_state()\n",
    "        recieved_parameter_size = get_parameters_size(ndarrays_to_parameters(parameters))  \n",
    "        set_parameters(self.net, parameters, config[\"updated_layers\"])\n",
    "\n",
    "        # load previous model\n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            prev_model = copy.deepcopy(self.net)\n",
    "        else:\n",
    "            # initialise and load params from model_dir\n",
    "            prev_model = type(self.net)() \n",
    "            prev_model.load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # create global model (same params that were just loaded)\n",
    "        global_model = type(self.net)()\n",
    "        global_model.load_state_dict(self.net.state_dict())\n",
    "        global_model.to(DEVICE)\n",
    "        \n",
    "\n",
    "        print(f\"trainable layers: {config}\")\n",
    "        freeze_layers(self.net, config[\"trainable_layers\"])\n",
    "        train_moon(self.net, self.trainloader, global_model, prev_model, EPOCHS, 5, 0.5)\n",
    "\n",
    "        # save current model \n",
    "        self._save_model_state()\n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            os.makedirs(os.path.join(self.model_dir, str(self.partition_id)))\n",
    "        torch.save(\n",
    "            self.net.state_dict(),\n",
    "            os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\"),\n",
    "        )\n",
    "\n",
    "        return self.get_parameters(config), len(self.trainloader), {\"trained_layer\": config[\"trainable_layers\"], \"recieved_parameter_size\": recieved_parameter_size}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        self._load_model_state()\n",
    "        current_params = get_parameters(self.net)\n",
    "        set_parameters(self.net, current_params)\n",
    "        loss, accuracy = test_moon(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    if not hasattr(context, 'net'):\n",
    "        context.net = MoonNet().to(DEVICE)\n",
    "    \n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedMoonPartFlowerClient(partition_id=partition_id,\n",
    "        net=context.net,\n",
    "        trainloader=trainloader,\n",
    "        valloader=valloader,\n",
    "        context=context).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)\n",
    "\n",
    "def get_evaluate_fn_moon(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test_moon(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FedMOON\n",
    "\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "net = MoonNet().to(DEVICE)\n",
    "evaluate_fn = get_evaluate_fn_moon(testloader, net)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedMoon(\n",
    "            evaluate_fn=evaluate_fn\n",
    "        )\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_moon_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_result, file)\n",
    "\n",
    "with open(f'results/fed_moon_model_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fed_part_moon_rounds = list(fed_moon_result.keys())\n",
    "# fed_part_moon_sizes = [fed_moon_result[round][\"total_size\"] for round in fed_part_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_sizes, marker='o', linestyle='-', color='b', label='FedMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_moon_losses = [fed_moon_result[round][\"total_loss\"] for round in fed_part_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_losses, marker='o', linestyle='-', color='b', label='FedMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_moon_model_rounds = list(fed_moon_model_results.keys())\n",
    "# fed_part_moon_accuracies = [fed_moon_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_part_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_accuracies, marker='o', linestyle='-', color='b', label='FedMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_part_moon_global_losses = [fed_moon_model_results[round][\"global_loss\"] for round in fed_part_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_global_losses, marker='o', linestyle='-', color='b', label='FedMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
