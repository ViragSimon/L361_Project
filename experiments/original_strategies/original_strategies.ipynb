{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=81465) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: urllib3==1.26.6 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib\n",
    "! pip install -U ipywidgets\n",
    "! pip install numpy==1.26.4\n",
    "! pip install urllib3==1.26.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mps\n",
      "Flower 1.15.1 / PyTorch 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple, Union, Callable\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr.server.strategy import Strategy\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context, Status, GetParametersRes, Parameters, GetParametersIns, MetricsAggregationFn,NDArrays,Scalar\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents \n",
    "from flwr.server.strategy import FedAvg, FedProx\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available:\n",
    "    DEVICE = \"mps\"\n",
    "else: \n",
    "    DEVICE = \"cpu\"\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        \n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self) -> None:\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool1 = nn.MaxPool2d(2, 2)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool2 = nn.MaxPool2d(2, 2)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool3 = nn.MaxPool2d(2, 2)\n",
    "#         self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool1(x)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         x = self.pool2(x)\n",
    "#         x = F.relu(self.conv5(x))\n",
    "#         x = F.relu(self.conv6(x))\n",
    "#         x = self.pool3(x)\n",
    "#         x = x.view(-1, 256*4*4)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MoonNet(nn.Module):\n",
    "    \"\"\"Returns both the representation (penultimate layer output) and classification\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(MoonNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        representation = x.clone()\n",
    "        classification = self.fc3(x)\n",
    "        return representation, classification\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters, trainable_layers=-1):\n",
    "    \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n",
    "    current_state = OrderedDict(net.state_dict())\n",
    "    \n",
    "    if trainable_layers == -1:\n",
    "        # Update all parameters\n",
    "        params_dict = zip(current_state.keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "    else:\n",
    "        # Only update the specified layer's parameters\n",
    "        # Convert current state to numpy arrays\n",
    "        numpy_state = [param.cpu().numpy() for param in current_state.values()]\n",
    "        \n",
    "        # Update the specific indices with new parameters\n",
    "        numpy_state[trainable_layers*2] = parameters[0]\n",
    "        numpy_state[trainable_layers*2 + 1] = parameters[1]\n",
    "        \n",
    "        # Convert back to torch and update state dict\n",
    "        for idx, key in enumerate(current_state.keys()):\n",
    "            current_state[key] = torch.from_numpy(numpy_state[idx])\n",
    "        \n",
    "        net.load_state_dict(current_state, strict=True)\n",
    "\n",
    "\n",
    "# def set_parameters(net, parameters: List[np.ndarray]):\n",
    "#     params_dict = zip(net.state_dict().keys(), parameters)\n",
    "#     state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "#     net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),betas=(0.999,0.999))\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "        \n",
    "def proxima_train(net, trainloader, epochs: int, proximal_mu:float, global_params:List[torch.Tensor]):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "\n",
    "            proximal_term = 0.0\n",
    "            for local_weights, global_weights in zip(net.parameters(), global_params):\n",
    "                proximal_term += (local_weights - global_weights).norm(2)\n",
    "            loss = criterion(net(images), labels) + (proximal_mu / 2) * proximal_term\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def train_moon(net,train_loader, global_net,previous_net, epochs, mu, temperature):\n",
    "    \"\"\"Training function for MOON.\"\"\"\n",
    "    print(f\"Started training moon\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    previous_net.eval()\n",
    "    global_net.eval()\n",
    "\n",
    "    cnt = 0\n",
    "    cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_collector = []\n",
    "        epoch_loss1_collector = []\n",
    "        epoch_loss2_collector = []\n",
    "        for batch in train_loader:\n",
    "            x, target = batch[\"img\"], batch[\"label\"]\n",
    "            x, target = x.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # pro1 is the representation by the current model (Line 14 of Algorithm 1)\n",
    "            pro1, out = net(x)\n",
    "            # pro2 is the representation by the global model (Line 15 of Algorithm 1)\n",
    "            # pro3 is the representation by the previous model (Line 16 of Algorithm 1)\n",
    "            with torch.no_grad():\n",
    "                pro2, _ = global_net(x)\n",
    "                pro3, _ = previous_net(x)\n",
    "\n",
    "            # posi is the positive pair\n",
    "            posi = cos(pro1, pro2)\n",
    "            logits = posi.reshape(-1, 1)\n",
    "\n",
    "            # nega is the negative pair\n",
    "            nega = cos(pro1, pro3)\n",
    "            logits = torch.cat((logits, nega.reshape(-1, 1)), dim=1)\n",
    "\n",
    "            previous_net.to(\"cpu\")\n",
    "            logits /= temperature\n",
    "            labels = torch.zeros(x.size(0)).to(DEVICE).long()\n",
    "\n",
    "            # compute the model-contrastive loss (Line 17 of Algorithm 1)\n",
    "            loss2 = mu * criterion(logits, labels)\n",
    "\n",
    "            # compute the cross-entropy loss (Line 13 of Algorithm 1)\n",
    "            loss1 = criterion(out, target)\n",
    "\n",
    "            # compute the loss (Line 18 of Algorithm 1)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cnt += 1\n",
    "            epoch_loss_collector.append(loss.item())\n",
    "            epoch_loss1_collector.append(loss1.item())\n",
    "            epoch_loss2_collector.append(loss2.item())\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
    "        epoch_loss1 = sum(epoch_loss1_collector) / len(epoch_loss1_collector)\n",
    "        epoch_loss2 = sum(epoch_loss2_collector) / len(epoch_loss2_collector)\n",
    "        print(\n",
    "            \"Epoch: %d Loss: %f Loss1: %f Loss2: %f\"\n",
    "            % (epoch, epoch_loss, epoch_loss1, epoch_loss2)\n",
    "        )\n",
    "\n",
    "\n",
    "def test_moon(net, testloader):\n",
    "    \"\"\"\n",
    "    Evaluate the network on the entire test set.\n",
    "    Same as the regular test, but using the MoonNet \n",
    "    (where the output is a tuple of (representation, classification) )\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            _, outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net = net.to(DEVICE) \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "# def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "#         \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "#         for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "#             if idx == trainable_layers or trainable_layers == -1:\n",
    "#                 param.requires_grad = True\n",
    "#             else:\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "        \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "        trainable_layers_set = []\n",
    "        if trainable_layers == -1:\n",
    "            trainable_layers_set = [-1]\n",
    "        else:\n",
    "            trainable_layers_set = [trainable_layers *2, trainable_layers *2 +1]\n",
    "\n",
    "        for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "            \n",
    "            if idx in trainable_layers_set or trainable_layers_set[0] == -1:\n",
    "                param.requires_grad = True\n",
    "                print(f\"layer index is {idx} and name{name} is trainabe\")\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                print(f\"layer index is {idx} and name{name} is frozen\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rounds: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NETWORK_LEN = len(Net().state_dict().keys()) //2 \n",
    "EPOCHS = 8\n",
    "NUM_PARTITIONS = 6\n",
    "NUM_OF_CYCLES  = 1\n",
    "NUM_OF_FULL_UPDATES_BETWEEN_CYCLES = 2\n",
    "NUM_OF_ROUNDS = (NUM_OF_CYCLES * NUM_OF_FULL_UPDATES_BETWEEN_CYCLES) + (NUM_OF_CYCLES * NETWORK_LEN *2)\n",
    "print(f\"Number of rounds: {NUM_OF_ROUNDS}\")\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays, Scalar\n",
    "import sys\n",
    "def get_evaluate_fn(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        loss, accuracy = test(net_copy, testloader)\n",
    "        \n",
    "        # Add a print statement here to debug\n",
    "        print(f\"Global evaluation - Loss: {loss}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "def get_evaluate_fn_moon(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test_moon(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "fed_avg_result = {}\n",
    "fed_avg_model_results = {}\n",
    "\n",
    "class ModifiedFedAvg(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartAvg\"\n",
    "    \n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "    \n",
    "   \n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "\n",
    "        if server_round in fed_avg_model_results:\n",
    "            expand_fed_avg_result= {**fed_avg_model_results[server_round], \"global_loss\": loss, \"global_metrics\": metrics}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"global_loss\": loss, \"global_metrics\": metrics}\n",
    "\n",
    "        fed_avg_model_results[server_round] = expand_fed_avg_result\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(parameters, config)))\n",
    "\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # get size of parameters in bytes\n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) *2\n",
    "        \n",
    "\n",
    "        if server_round in fed_avg_result:\n",
    "            expand_fed_avg_result= {**fed_avg_result[server_round], \"total_size\": total_size}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"total_size\": total_size}\n",
    "\n",
    "        fed_avg_result[server_round] = expand_fed_avg_result\n",
    "\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss \n",
    "\n",
    "\n",
    "        if server_round in fed_avg_result:\n",
    "            expand_fed_avg_result= {**fed_avg_result[server_round], \"total_loss\": total_loss}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"total_loss\": total_loss}\n",
    "\n",
    "        fed_avg_result[server_round] = expand_fed_avg_result\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return NormalFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=12, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07214769554138184, {'accuracy': 0.1}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.07214769554138184, Accuracy: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 1: train loss 0.06525389850139618, accuracy 0.21662166216621662\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 3: train loss 0.055816784501075745, accuracy 0.3442844284428443\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 5: train loss 0.050122734159231186, accuracy 0.4147914791479148\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 7: train loss 0.04700985178351402, accuracy 0.45484548454845486\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.06243520519733429, {'accuracy': 0.2946}, 39.3808312502224)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.06243520519733429, Accuracy: 0.2946\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m Epoch 8: train loss 0.046257149428129196, accuracy 0.444044404440444\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 1: train loss 0.05226302519440651, accuracy 0.3789378937893789\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 2: train loss 0.047875188291072845, accuracy 0.43767811609419527\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 4: train loss 0.04457440599799156, accuracy 0.4744974497449745\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 5: train loss 0.0424310564994812, accuracy 0.511324433778311\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 7: train loss 0.040560927242040634, accuracy 0.5192019201920192\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.04231188372969628, {'accuracy': 0.506}, 78.49786237510853)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.04231188372969628, Accuracy: 0.506\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 8: train loss 0.03808918222784996, accuracy 0.5626218689065546\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 1: train loss 0.04421223700046539, accuracy 0.4801980198019802\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m Epoch 3: train loss 0.036757905036211014, accuracy 0.5703570357035703\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m Epoch 5: train loss 0.03383428975939751, accuracy 0.6074107410741074\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m Epoch 7: train loss 0.03084646351635456, accuracy 0.6477647764776477\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.03958990616798401, {'accuracy': 0.5499}, 115.21811433299445)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03958990616798401, Accuracy: 0.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 8: train loss 0.03274637460708618, accuracy 0.6257687115644218\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 1: train loss 0.040093131363391876, accuracy 0.5336033603360336\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 2: train loss 0.03673867881298065, accuracy 0.5826582658265826\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 4: train loss 0.03345649689435959, accuracy 0.60996099609961\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 6: train loss 0.030110657215118408, accuracy 0.6537653765376538\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 8: train loss 0.026720449328422546, accuracy 0.6957695769576958\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.03836605664491653, {'accuracy': 0.5716}, 148.85168816614896)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03836605664491653, Accuracy: 0.5716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m Epoch 8: train loss 0.02693583071231842, accuracy 0.6911191119111911\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 1: train loss 0.03867991641163826, accuracy 0.5566221688915555\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 3: train loss 0.033292368054389954, accuracy 0.6125693715314234\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 5: train loss 0.029264070093631744, accuracy 0.6628168591570421\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 7: train loss 0.024755192920565605, accuracy 0.7098709870987099\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.03856569681167603, {'accuracy': 0.5851}, 180.75360233313404)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03856569681167603, Accuracy: 0.5851\n",
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 8: train loss 0.023289719596505165, accuracy 0.7275727572757276\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 1: train loss 0.03619168698787689, accuracy 0.5882088208820883\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 3: train loss 0.029094088822603226, accuracy 0.668016801680168\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m Epoch 5: train loss 0.024734776467084885, accuracy 0.7118211821182118\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m Epoch 7: train loss 0.02078309841454029, accuracy 0.7638763876387639\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.03938808216452599, {'accuracy': 0.5901}, 215.14189454121515)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03938808216452599, Accuracy: 0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m Epoch 8: train loss 0.02192629873752594, accuracy 0.7476747674767477\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 1: train loss 0.034415651112794876, accuracy 0.6119694015299235\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7505)\u001b[0m Epoch 3: train loss 0.02643556334078312, accuracy 0.695919591959196\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 5: train loss 0.023183070123195648, accuracy 0.7387130643467826\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 6: train loss 0.0218353271484375, accuracy 0.7538623068846557\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m Epoch 8: train loss 0.018275447189807892, accuracy 0.7922603869806509\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.040221964049339295, {'accuracy': 0.5952}, 253.83685808302835)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.040221964049339295, Accuracy: 0.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m Epoch 8: train loss 0.018383005633950233, accuracy 0.7857785778577858\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7509)\u001b[0m Epoch 1: train loss 0.03094295598566532, accuracy 0.648064806480648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m Epoch 1: train loss 0.032840728759765625, accuracy 0.6248124812481248\n",
      "\u001b[36m(ClientAppActor pid=7507)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7506)\u001b[0m Epoch 2: train loss 0.027781302109360695, accuracy 0.6836658167091645\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7504)\u001b[0m Epoch 3: train loss 0.02498200535774231, accuracy 0.7133213321332134\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=7508)\u001b[0m Epoch 5: train loss 0.02137073129415512, accuracy 0.7544254425442545\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=ModifiedFedAvg(\n",
    "            evaluate_fn=evaluate_fn\n",
    "        ),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "with open(f'results/fed_avg_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_avg_result, file)\n",
    "\n",
    "with open(f'results/fed_avg_model_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_avg_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# fed_avg_rounds = list(fed_avg_result.keys())\n",
    "# fed_avg_sizes = [fed_avg_result[round][\"total_size\"] for round in fed_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_avg_losses = [fed_avg_result[round][\"total_loss\"] for round in fed_avg_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_avg_model_rounds = list(fed_avg_model_results.keys())\n",
    "\n",
    "# fed_avg_accuracies = [fed_avg_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_avg_global_losses = [fed_avg_model_results[round][\"global_loss\"] for round in fed_avg_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss for Each Round')\n",
    "# plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedProx experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProxFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        global_params = copy.deepcopy(self.net).parameters()\n",
    "        proxima_train(self.net, self.trainloader, EPOCHS, config[\"proximal_mu\"], global_params)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedProxFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_prox_result = {}\n",
    "\n",
    "fed_prox_model_results = {}\n",
    "\n",
    "class ModifiedFedProx(ModifiedFedAvg):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        proximal_mu: float,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_evaluate=fraction_evaluate,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_evaluate_clients=min_evaluate_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            evaluate_fn=evaluate_fn,\n",
    "            on_fit_config_fn=on_fit_config_fn,\n",
    "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "            accept_failures=accept_failures,\n",
    "            initial_parameters=initial_parameters,\n",
    "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        )\n",
    "        self.proximal_mu = proximal_mu\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ModifiedFedProx\"\n",
    "    \n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> list[tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\n",
    "\n",
    "        Sends the proximal factor mu to the clients\n",
    "        \"\"\"\n",
    "        # Get the standard client/config pairs from the FedAvg super-class\n",
    "        client_config_pairs = super().configure_fit(\n",
    "            server_round, parameters, client_manager\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs with the proximal factor mu added\n",
    "        return [\n",
    "            (\n",
    "                client,\n",
    "                FitIns(\n",
    "                    fit_ins.parameters,\n",
    "                    {**fit_ins.config, \"proximal_mu\": self.proximal_mu},\n",
    "                ),\n",
    "            )\n",
    "            for client, fit_ins in client_config_pairs\n",
    "        ]\n",
    "    \n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) *2\n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        if fed_prox_result.get(server_round):\n",
    "            fed_prox_result[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_prox_result[server_round] = {\"total_size\": total_size}\n",
    "        \n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_prox_result.get(server_round):\n",
    "            fed_prox_result[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_prox_result[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "    \n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_prox_model_results:  \n",
    "            expand_fed_prox_model_results= {**fed_prox_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_prox_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_prox_model_results[server_round] = expand_fed_prox_model_results\n",
    "        \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=12, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07214184160232544, {'accuracy': 0.1}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.07214184160232544, Accuracy: 0.1\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m Epoch 1: train loss 0.0629144236445427, accuracy 0.25622562256225623\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 4: train loss 0.0479242317378521, accuracy 0.445994599459946\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.05583519825935364, {'accuracy': 0.4115}, 21.51567408302799)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.05583519825935364, Accuracy: 0.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.046532999724149704, accuracy 0.4561956195619562\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 1: train loss 0.049462612718343735, accuracy 0.42529252925292527\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 1: train loss 0.049727022647857666, accuracy 0.424028798560072\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 2] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 3: train loss 0.04234517738223076, accuracy 0.5168016801680168\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.04088206272125244, {'accuracy': 0.5281}, 41.04496841598302)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.04088206272125244, Accuracy: 0.5281\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.03742179274559021, accuracy 0.5726072607260726\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 1] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m Epoch 1: train loss 0.04104507714509964, accuracy 0.5255737213139343\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m Epoch 1: train loss 0.0410582609474659, accuracy 0.5328532853285328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 5] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 2: train loss 0.03809734061360359, accuracy 0.5612061206120612\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 5: train loss 0.02948327362537384, accuracy 0.6648664866486649\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.03810113791823387, {'accuracy': 0.574}, 62.50093924999237)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03810113791823387, Accuracy: 0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 1] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m Epoch 1: train loss 0.03557122126221657, accuracy 0.5984098409840984\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 4: train loss 0.027369467541575432, accuracy 0.6989650517474126\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.03784473740458488, {'accuracy': 0.5937}, 81.959695416037)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03784473740458488, Accuracy: 0.5937\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 5: train loss 0.024613304063677788, accuracy 0.7284728472847285\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 1] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 1: train loss 0.033781491219997406, accuracy 0.6133193340332983\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m Epoch 1: train loss 0.03424597159028053, accuracy 0.6084608460846085\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 4: train loss 0.022453393787145615, accuracy 0.7561121943902804\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.03886628119945526, {'accuracy': 0.6}, 100.12261366611347)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.03886628119945526, Accuracy: 0.6\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.018572743982076645, accuracy 0.7901604919754013\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m Epoch 1: train loss 0.030496040359139442, accuracy 0.6596159615961597\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 1: train loss 0.03218017891049385, accuracy 0.6434678266086695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 1] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 3: train loss 0.021864984184503555, accuracy 0.7563756375637564\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m Epoch 5: train loss 0.01478562317788601, accuracy 0.8424842484248425\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.04159806432127953, {'accuracy': 0.6004}, 122.54511679103598)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.04159806432127953, Accuracy: 0.6004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.014831376262009144, accuracy 0.8351582420878956\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m Epoch 1: train loss 0.029667621478438377, accuracy 0.6637168141592921\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 1: train loss 0.030141307041049004, accuracy 0.663066306630663\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 3: train loss 0.01865173690021038, accuracy 0.7904290429042904\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.011849718168377876, accuracy 0.8708370837083709\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.04508976762890816, {'accuracy': 0.5991}, 142.24871308309957)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.04508976762890816, Accuracy: 0.5991\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 5] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 1: train loss 0.029035288840532303, accuracy 0.6696669666966697\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 4: train loss 0.01262921467423439, accuracy 0.8642364236423642\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 2] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 2: train loss 0.020268632099032402, accuracy 0.7779777977797779\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 5: train loss 0.009762666188180447, accuracy 0.8958895889588959\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.048097110426425935, {'accuracy': 0.5993}, 167.75286641600542)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.048097110426425935, Accuracy: 0.5993\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m Epoch 1: train loss 0.027360159903764725, accuracy 0.6977651117444128\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 4: train loss 0.009793645702302456, accuracy 0.8939553022348883\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.0516355470597744, {'accuracy': 0.599}, 187.08824066608213)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.0516355470597744, Accuracy: 0.599\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 5: train loss 0.007237080950289965, accuracy 0.9281428142814282\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 1: train loss 0.02545180357992649, accuracy 0.7221722172217222\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 1: train loss 0.02661379985511303, accuracy 0.7034203420342034\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 4: train loss 0.007989131845533848, accuracy 0.9158415841584159\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.05683662296533585, {'accuracy': 0.5959}, 206.58023375016637)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.05683662296533585, Accuracy: 0.5959\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 5: train loss 0.006334460340440273, accuracy 0.9340032998350083\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m Epoch 1: train loss 0.024614686146378517, accuracy 0.7346234623462347\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m Epoch 1: train loss 0.024992380291223526, accuracy 0.7244224422442245\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 3: train loss 0.010346639901399612, accuracy 0.8862886288628863\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (11, 0.05908734547495842, {'accuracy': 0.5941}, 225.08319229097106)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.05908734547495842, Accuracy: 0.5941\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 5: train loss 0.0056945206597447395, accuracy 0.943752812359382\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m [Client 4] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 1: train loss 0.023803018033504486, accuracy 0.7445244524452446\n",
      "\u001b[36m(ClientAppActor pid=8319)\u001b[0m Epoch 1: train loss 0.024422675371170044, accuracy 0.7339133043347833\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8321)\u001b[0m Epoch 4: train loss 0.005926772486418486, accuracy 0.9401440144014401\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 2999040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (12, 0.06339455078244209, {'accuracy': 0.5921}, 244.32426258316264)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global evaluation - Loss: 0.06339455078244209, Accuracy: 0.5921\n",
      "\u001b[36m(ClientAppActor pid=8317)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=8318)\u001b[0m Epoch 5: train loss 0.005570672452449799, accuracy 0.9462946294629463\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8320)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 12 round(s) in 248.58s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.05695787315915952\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04175951690155134\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.038860283151397085\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.038648767706317394\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.039778891603718086\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.04245531879338627\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.045815323573145904\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.04910989064619711\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.05219045401079861\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.057017360321158374\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.05971014287965803\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.06340603573248535\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.07214184160232544\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.05583519825935364\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04088206272125244\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.03810113791823387\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.03784473740458488\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.03886628119945526\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.04159806432127953\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.04508976762890816\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.048097110426425935\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.0516355470597744\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.05683662296533585\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.05908734547495842\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.06339455078244209\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (1, 0.4115),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5281),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.574),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5937),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.6),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.6004),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.5991),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.5993),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.599),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.5959),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.5941),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.5921)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=8316)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=ModifiedFedProx(proximal_mu=0.1, evaluate_fn=evaluate_fn),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_prox_result.p', 'wb') as file:\n",
    "    pickle.dump(fed_prox_result, file)\n",
    "\n",
    "with open(f'results/fed_prox_model_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_prox_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_prox_rounds = list(fed_prox_result.keys())\n",
    "fed_prox_sizes = [fed_prox_result[round][\"total_size\"] for round in fed_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_prox_rounds, fed_prox_sizes, marker='o', linestyle='-', color='b', label='FedProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_prox_losses = [fed_prox_result[round][\"total_loss\"] for round in fed_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_prox_rounds, fed_prox_losses, marker='o', linestyle='-', color='b', label='FedProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_prox_model_rounds = list(fed_prox_model_results.keys())\n",
    "# fed_prox_accuracies = [fed_prox_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(fed_part_prox_model_rounds, fed_part_prox_accuracies, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_prox_global_losses = [fed_prox_model_results[round][\"global_loss\"] for round in fed_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(fed_part_prox_model_rounds, fed_part_prox_global_losses, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')   \n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedMoon experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class FedMoonNoFreezeFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model_dir = \"models\"\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        trainable_layer = config[\"trainable_layers\"]\n",
    "        self._save_model_state()\n",
    "        \n",
    "        if trainable_layer == -1:\n",
    "            return parameters\n",
    "        \n",
    "        trained_layer = [parameters[trainable_layer*2], parameters[trainable_layer*2 +1]]\n",
    "        return trained_layer\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "\n",
    "        # load previous model\n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            prev_model = copy.deepcopy(self.net)\n",
    "        else:\n",
    "            # initialise and load params from model_dir\n",
    "            prev_model = type(self.net)() \n",
    "            prev_model.load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # update params for current model (loading global params)\n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "        # create global model (same params that were just loaded)\n",
    "        global_model = type(self.net)()\n",
    "        global_model.load_state_dict(self.net.state_dict())\n",
    "        global_model.to(DEVICE)\n",
    "        \n",
    "        train_moon(self.net, self.trainloader, global_model, prev_model, EPOCHS, 5, 0.5)\n",
    "\n",
    "        # save current model \n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            os.makedirs(os.path.join(self.model_dir, str(self.partition_id)))\n",
    "        torch.save(\n",
    "            self.net.state_dict(),\n",
    "            os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\"),\n",
    "        )\n",
    "\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test_moon(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = MoonNet().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedMoonNoFreezeFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import sys\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n",
    "\n",
    "fed_moon_no_freeze_result = {}\n",
    "fed_moon_model_no_freeze_results = {}\n",
    "\n",
    "# basically same as normal FedAvg, just added freezing and modified result dict names\n",
    "class FedMoonNoFreeze(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedMoon\"\n",
    "    \n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "   \n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "\n",
    "        if server_round in fed_moon_model_no_freeze_results:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_model_no_freeze_results[server_round], \"global_loss\": loss, \"global_metrics\": metrics}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"global_loss\": loss, \"global_metrics\": metrics}\n",
    "\n",
    "        fed_moon_model_no_freeze_results[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "    def configure_fit(\n",
    "        # includes layer freezing\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        config = {}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(parameters, config)))\n",
    "\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # get size of parameters in bytes\n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) * 2\n",
    "        \n",
    "        if server_round in fed_moon_no_freeze_result:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_no_freeze_result[server_round], \"total_size\": total_size}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"total_size\": total_size}\n",
    "\n",
    "        fed_moon_no_freeze_result[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        \n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        \n",
    "        self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        return self.latest_parameters, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss \n",
    "\n",
    "\n",
    "        if server_round in fed_moon_no_freeze_result:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_no_freeze_result[server_round], \"total_loss\": total_loss}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"total_loss\": total_loss}\n",
    "\n",
    "        fed_moon_no_freeze_result[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=12, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: Error(s) in loading state_dict for MoonNet:\n",
      "\tMissing key(s) in state_dict: \"conv6.weight\", \"conv6.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n",
      "\tsize mismatch for conv1.weight: copying a param with shape torch.Size([6, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 3, 3, 3]).\n",
      "\tsize mismatch for conv1.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for conv2.weight: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n",
      "\tsize mismatch for conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for conv3.weight: copying a param with shape torch.Size([120, 400]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "\tsize mismatch for conv3.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv4.weight: copying a param with shape torch.Size([84, 120]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "\tsize mismatch for conv4.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv5.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "\tsize mismatch for conv5.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/run_serverapp.py\", line 63, in run\n",
      "    server_app(driver=driver, context=context)\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server_app.py\", line 120, in __call__\n",
      "    start_driver(\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/compat/app.py\", line 87, in start_driver\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/ipykernel_81465/741609897.py\", line 101, in evaluate\n",
      "    eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/ipykernel_81465/452179305.py\", line 48, in evaluate\n",
      "    net_copy.load_state_dict(state_dict, strict=True)\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for MoonNet:\n",
      "\tMissing key(s) in state_dict: \"conv6.weight\", \"conv6.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n",
      "\tsize mismatch for conv1.weight: copying a param with shape torch.Size([6, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 3, 3, 3]).\n",
      "\tsize mismatch for conv1.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for conv2.weight: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n",
      "\tsize mismatch for conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for conv3.weight: copying a param with shape torch.Size([120, 400]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "\tsize mismatch for conv3.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv4.weight: copying a param with shape torch.Size([84, 120]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "\tsize mismatch for conv4.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv5.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "\tsize mismatch for conv5.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\n",
      "Exception in thread Thread-21 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/run_serverapp.py\", line 63, in run\n",
      "    server_app(driver=driver, context=context)\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server_app.py\", line 120, in __call__\n",
      "    start_driver(\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/compat/app.py\", line 87, in start_driver\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/server/server.py\", line 95, in fit\n",
      "    res = self.strategy.evaluate(0, parameters=self.parameters)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/ipykernel_81465/741609897.py\", line 101, in evaluate\n",
      "  File \"/var/folders/6j/51pt41xs611cqzmtybytnss40000gn/T/ipykernel_81465/452179305.py\", line 48, in evaluate\n",
      "  File \"/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for MoonNet:\n",
      "\tMissing key(s) in state_dict: \"conv6.weight\", \"conv6.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n",
      "\tsize mismatch for conv1.weight: copying a param with shape torch.Size([6, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([32, 3, 3, 3]).\n",
      "\tsize mismatch for conv1.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for conv2.weight: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n",
      "\tsize mismatch for conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for conv3.weight: copying a param with shape torch.Size([120, 400]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n",
      "\tsize mismatch for conv3.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv4.weight: copying a param with shape torch.Size([84, 120]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "\tsize mismatch for conv4.bias: copying a param with shape torch.Size([84]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for conv5.weight: copying a param with shape torch.Size([10, 84]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "\tsize mismatch for conv5.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([256]).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m server \u001b[38;5;241m=\u001b[39m ServerApp(server_fn\u001b[38;5;241m=\u001b[39mserver_fn)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run simulation\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_PARTITIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:211\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[1;32m    203\u001b[0m     warn_deprecated_feature_with_example(\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m         example_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 211\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEventType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:510\u001b[0m, in \u001b[0;36m_run_simulation\u001b[0;34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m         logger \u001b[38;5;241m=\u001b[39m set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 510\u001b[0m     updated_context \u001b[38;5;241m=\u001b[39m \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "File \u001b[0;32m~/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:408\u001b[0m, in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    406\u001b[0m         serverapp_th\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 408\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in ServerApp thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    410\u001b[0m log(DEBUG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping Simulation Engine now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "# Train FedMOON\n",
    "\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "net = MoonNet().to(DEVICE)\n",
    "evaluate_fn = get_evaluate_fn_moon(testloader, net)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedMoonNoFreeze(\n",
    "            evaluate_fn=evaluate_fn\n",
    "        )\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_moon_no_freeze_result.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_no_freeze_result, file)\n",
    "\n",
    "with open(f'results/fed_moon_model_no_freeze_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_model_no_freeze_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fed_moon_rounds = list(fed_moon_no_freeze_result.keys())\n",
    "# fed_moon_sizes = [fed_moon_no_freeze_result[round][\"total_size\"] for round in fed_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_rounds, fed_prox_sizes, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_sizes, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_rounds, fed_moon_sizes, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_sizes, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Communication Cost (bytes)')\n",
    "# plt.title('Communication Cost for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_losses = [fed_moon_no_freeze_result[round][\"total_loss\"] for round in fed_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_rounds, fed_prox_losses, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_losses, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_rounds, fed_moon_losses, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_losses, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Aggregate Client Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_model_rounds = list(fed_moon_model_no_freeze_results.keys())\n",
    "# fed_moon_accuracies = [fed_moon_model_no_freeze_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_model_rounds, fed_prox_accuracies, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_accuracies, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_model_rounds, fed_moon_accuracies, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_accuracies, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Global Model Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_global_losses = [fed_moon_model_no_freeze_results[round][\"global_loss\"] for round in fed_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_model_rounds, fed_prox_global_losses, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_global_losses, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_model_rounds, fed_moon_global_losses, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_global_losses, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Global Model Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
