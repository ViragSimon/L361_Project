{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: urllib3==1.26.6 in /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib\n",
    "! pip install -U ipywidgets\n",
    "! pip install numpy==1.26.4\n",
    "! pip install urllib3==1.26.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.15.2 / PyTorch 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple, Union, Callable\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr.server.strategy import Strategy\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context, Status, GetParametersRes, Parameters, GetParametersIns, MetricsAggregationFn,NDArrays,Scalar\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents \n",
    "from flwr.server.strategy import FedAvg, FedProx\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    "    ParametersRecord,\n",
    "    array_from_numpy\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available:\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available:\n",
    "    DEVICE = \"mps\"\n",
    "else: \n",
    "    DEVICE = \"cpu\"\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    drichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=0.1, partition_by=\"label\")\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": drichlet_partitioner})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        \n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MoonNet(nn.Module):\n",
    "    \"\"\"Returns both the representation (penultimate layer output) and classification\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(MoonNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        representation = x.clone()\n",
    "        classification = self.fc3(x)\n",
    "        return representation, classification\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters, trainable_layers=-1):\n",
    "    \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n",
    "    current_state = OrderedDict(net.state_dict())\n",
    "    \n",
    "    if trainable_layers == -1:\n",
    "        # Update all parameters\n",
    "        params_dict = zip(current_state.keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "    else:\n",
    "        # Only update the specified layer's parameters\n",
    "        # Convert current state to numpy arrays\n",
    "        numpy_state = [param.cpu().numpy() for param in current_state.values()]\n",
    "        \n",
    "        # Update the specific indices with new parameters\n",
    "        numpy_state[trainable_layers*2] = parameters[0]\n",
    "        numpy_state[trainable_layers*2 + 1] = parameters[1]\n",
    "        \n",
    "        # Convert back to torch and update state dict\n",
    "        for idx, key in enumerate(current_state.keys()):\n",
    "            current_state[key] = torch.from_numpy(numpy_state[idx])\n",
    "        \n",
    "        net.load_state_dict(current_state, strict=True)\n",
    "\n",
    "\n",
    "# def set_parameters(net, parameters: List[np.ndarray]):\n",
    "#     params_dict = zip(net.state_dict().keys(), parameters)\n",
    "#     state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "#     net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),betas=(0.999,0.999))\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "        \n",
    "def proxima_train(net, trainloader, epochs: int, proximal_mu:float, global_params:List[torch.Tensor]):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "\n",
    "            proximal_term = 0.0\n",
    "            for local_weights, global_weights in zip(net.parameters(), global_params):\n",
    "                proximal_term += (local_weights - global_weights).norm(2)\n",
    "            loss = criterion(net(images), labels) + (proximal_mu / 2) * proximal_term\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def train_moon(net,train_loader, global_net,previous_net, epochs, mu, temperature):\n",
    "    \"\"\"Training function for MOON.\"\"\"\n",
    "    print(f\"Started training moon\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    previous_net.eval()\n",
    "    global_net.eval()\n",
    "\n",
    "    cnt = 0\n",
    "    cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_collector = []\n",
    "        epoch_loss1_collector = []\n",
    "        epoch_loss2_collector = []\n",
    "        for batch in train_loader:\n",
    "            x, target = batch[\"img\"], batch[\"label\"]\n",
    "            x, target = x.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # pro1 is the representation by the current model (Line 14 of Algorithm 1)\n",
    "            pro1, out = net(x)\n",
    "            # pro2 is the representation by the global model (Line 15 of Algorithm 1)\n",
    "            # pro3 is the representation by the previous model (Line 16 of Algorithm 1)\n",
    "            with torch.no_grad():\n",
    "                pro2, _ = global_net(x)\n",
    "                pro3, _ = previous_net(x)\n",
    "\n",
    "            # posi is the positive pair\n",
    "            posi = cos(pro1, pro2)\n",
    "            logits = posi.reshape(-1, 1)\n",
    "\n",
    "            # nega is the negative pair\n",
    "            nega = cos(pro1, pro3)\n",
    "            logits = torch.cat((logits, nega.reshape(-1, 1)), dim=1)\n",
    "\n",
    "            previous_net.to(\"cpu\")\n",
    "            logits /= temperature\n",
    "            labels = torch.zeros(x.size(0)).to(DEVICE).long()\n",
    "\n",
    "            # compute the model-contrastive loss (Line 17 of Algorithm 1)\n",
    "            loss2 = mu * criterion(logits, labels)\n",
    "\n",
    "            # compute the cross-entropy loss (Line 13 of Algorithm 1)\n",
    "            loss1 = criterion(out, target)\n",
    "\n",
    "            # compute the loss (Line 18 of Algorithm 1)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cnt += 1\n",
    "            epoch_loss_collector.append(loss.item())\n",
    "            epoch_loss1_collector.append(loss1.item())\n",
    "            epoch_loss2_collector.append(loss2.item())\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
    "        epoch_loss1 = sum(epoch_loss1_collector) / len(epoch_loss1_collector)\n",
    "        epoch_loss2 = sum(epoch_loss2_collector) / len(epoch_loss2_collector)\n",
    "        print(\n",
    "            \"Epoch: %d Loss: %f Loss1: %f Loss2: %f\"\n",
    "            % (epoch, epoch_loss, epoch_loss1, epoch_loss2)\n",
    "        )\n",
    "\n",
    "\n",
    "def test_moon(net, testloader):\n",
    "    \"\"\"\n",
    "    Evaluate the network on the entire test set.\n",
    "    Same as the regular test, but using the MoonNet \n",
    "    (where the output is a tuple of (representation, classification) )\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            _, outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "# def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "#         \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "#         for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "#             if idx == trainable_layers or trainable_layers == -1:\n",
    "#                 param.requires_grad = True\n",
    "#             else:\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "def freeze_layers(model: torch.nn.Module, trainable_layers: int) -> None:\n",
    "        \"\"\"Freeze specified layers of the model.\"\"\"\n",
    "        trainable_layers_set = []\n",
    "        if trainable_layers == -1:\n",
    "            trainable_layers_set = [-1]\n",
    "        else:\n",
    "            trainable_layers_set = [trainable_layers *2, trainable_layers *2 +1]\n",
    "\n",
    "        for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "            \n",
    "            if idx in trainable_layers_set or trainable_layers_set[0] == -1:\n",
    "                param.requires_grad = True\n",
    "                print(f\"layer index is {idx} and name{name} is trainabe\")\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                print(f\"layer index is {idx} and name{name} is frozen\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rounds: 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NETWORK_LEN = len(Net().state_dict().keys()) //2 \n",
    "EPOCHS = 5\n",
    "NUM_PARTITIONS = 6\n",
    "NUM_OF_CYCLES  = 1\n",
    "NUM_OF_FULL_UPDATES_BETWEEN_CYCLES = 2\n",
    "NUM_OF_ROUNDS = (NUM_OF_CYCLES * NUM_OF_FULL_UPDATES_BETWEEN_CYCLES) + (NUM_OF_CYCLES * NETWORK_LEN *2)\n",
    "print(f\"Number of rounds: {NUM_OF_ROUNDS}\")\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import NDArrays, Scalar\n",
    "import sys\n",
    "def get_evaluate_fn(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "def get_evaluate_fn_moon(\n",
    "    testloader: DataLoader,\n",
    "    net: torch.nn.Module,\n",
    ") -> Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]:\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Use the entire test set for evaluation.\"\"\"\n",
    "        \n",
    "        # Copy model parameters to avoid modifying the original\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        params_dict = zip(net_copy.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net_copy.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        net_copy.to(DEVICE)\n",
    "        net_copy.eval()\n",
    "\n",
    "        # Test the model\n",
    "        loss, accuracy = test_moon(net_copy, testloader)\n",
    "        \n",
    "        # Return loss and metrics\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "fed_avg_result = {}\n",
    "fed_avg_model_results = {}\n",
    "\n",
    "class ModifiedFedAvg(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedPartAvg\"\n",
    "    \n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "    \n",
    "   \n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "    \n",
    "\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "\n",
    "        if server_round in fed_avg_model_results:\n",
    "            expand_fed_avg_result= {**fed_avg_model_results[server_round], \"global_loss\": loss, \"global_metrics\": metrics}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"global_loss\": loss, \"global_metrics\": metrics}\n",
    "\n",
    "        fed_avg_model_results[server_round] = expand_fed_avg_result\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        \n",
    "        config = {}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(parameters, config)))\n",
    "\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # get size of parameters in bytes\n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) *2\n",
    "        \n",
    "\n",
    "        if server_round in fed_avg_result:\n",
    "            expand_fed_avg_result= {**fed_avg_result[server_round], \"total_size\": total_size}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"total_size\": total_size}\n",
    "\n",
    "        fed_avg_result[server_round] = expand_fed_avg_result\n",
    "\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss \n",
    "\n",
    "\n",
    "        if server_round in fed_avg_result:\n",
    "            expand_fed_avg_result= {**fed_avg_result[server_round], \"total_loss\": total_loss}\n",
    "        else:\n",
    "            expand_fed_avg_result= {\"total_loss\": total_loss}\n",
    "\n",
    "        fed_avg_result[server_round] = expand_fed_avg_result\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return NormalFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=20, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07208140110969544, {'accuracy': 0.1}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m [Client 3] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 1: train loss 0.05625765770673752, accuracy 0.30303702061627136\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 1: train loss 0.023608405143022537, accuracy 0.6377257799671593\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 1: train loss 0.029315484687685966, accuracy 0.5539071680376029\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 1: train loss 0.05001211538910866, accuracy 0.27889022919179735\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 2: train loss 0.053257767111063004, accuracy 0.34648636665927735\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 2: train loss 0.021062998101115227, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 3: train loss 0.05309157446026802, accuracy 0.34648636665927735\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 2: train loss 0.023890644311904907, accuracy 0.6775244299674267\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 2: train loss 0.04749708250164986, accuracy 0.2808202653799759\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 4: train loss 0.05298607051372528, accuracy 0.34648636665927735\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 4: train loss 0.02095174230635166, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 3: train loss 0.01816122978925705, accuracy 0.806551116333725\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 3: train loss 0.019026001915335655, accuracy 0.7615068687154793\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 5: train loss 0.05263619124889374, accuracy 0.34648636665927735\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 5: train loss 0.02101326920092106, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 3: train loss 0.04758040979504585, accuracy 0.2893848009650181\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 4: train loss 0.016881128773093224, accuracy 0.8181551116333725\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 4: train loss 0.01529789436608553, accuracy 0.8034272765897181\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 4: train loss 0.04702470824122429, accuracy 0.28323281061519906\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 4: train loss 0.035115018486976624, accuracy 0.4718543046357616\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 5: train loss 0.01604331098496914, accuracy 0.8321092831962397\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 5: train loss 0.012589839287102222, accuracy 0.8487466364537601\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 5: train loss 0.045104239135980606, accuracy 0.3235223160434258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 5: train loss 0.035089991986751556, accuracy 0.4718543046357616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.07279015896320343, {'accuracy': 0.1}, 511.7593721250305)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 1: train loss 0.05671091750264168, accuracy 0.2731101751274662\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 1: train loss 0.042642343789339066, accuracy 0.4240599294947121\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 1: train loss 0.05070860683917999, accuracy 0.2629674306393245\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 2: train loss 0.05401841551065445, accuracy 0.3045887829749501\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 1: train loss 0.04545889049768448, accuracy 0.4147350993377483\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 3: train loss 0.053755294531583786, accuracy 0.34648636665927735\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 2: train loss 0.03426456078886986, accuracy 0.36850304489449087\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 3: train loss 0.022689906880259514, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 2: train loss 0.047881923615932465, accuracy 0.2822677925211098\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 2: train loss 0.03720788657665253, accuracy 0.4718543046357616\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 4: train loss 0.0531526654958725, accuracy 0.34648636665927735\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 4: train loss 0.02136906422674656, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 3: train loss 0.028191013261675835, accuracy 0.5850470035252644\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 3: train loss 0.03323096036911011, accuracy 0.4614077326157768\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m Epoch 5: train loss 0.053111668676137924, accuracy 0.34648636665927735\n",
      "\u001b[36m(ClientAppActor pid=45754)\u001b[0m Epoch 5: train loss 0.021260259672999382, accuracy 0.6921182266009852\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 3: train loss 0.04785379767417908, accuracy 0.2634499396863691\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 3: train loss 0.03662216290831566, accuracy 0.43980605487228003\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 4: train loss 0.0278989989310503, accuracy 0.5850470035252644\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 4: train loss 0.03270838409662247, accuracy 0.46948024359155927\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 4: train loss 0.047622308135032654, accuracy 0.28636911942098914\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m Epoch 5: train loss 0.028373129665851593, accuracy 0.5850470035252644\n",
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 4: train loss 0.03548102453351021, accuracy 0.4713812677388836\n",
      "\u001b[36m(ClientAppActor pid=45751)\u001b[0m Epoch 5: train loss 0.032667387276887894, accuracy 0.46948024359155927\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m Epoch 5: train loss 0.047579120844602585, accuracy 0.2640530759951749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45755)\u001b[0m Epoch 5: train loss 0.035186298191547394, accuracy 0.4718543046357616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.0736135172367096, {'accuracy': 0.1}, 1041.5817442920525)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=45752)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45750)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=45753)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=ModifiedFedAvg(\n",
    "            evaluate_fn=evaluate_fn\n",
    "        ),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "with open(f'results/fed_avg_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_avg_result, file)\n",
    "\n",
    "with open(f'results/fed_avg_model_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_avg_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fed_avg_rounds = list(fed_avg_result.keys())\n",
    "fed_avg_sizes = [fed_avg_result[round][\"total_size\"] for round in fed_avg_rounds]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Total Size of Parameters (bytes)')\n",
    "plt.title('Total Size of Parameters for Each Round')\n",
    "plt.grid(True)\n",
    "\n",
    "fed_avg_losses = [fed_avg_result[round][\"total_loss\"] for round in fed_avg_rounds]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Total Loss for Each Round')\n",
    "plt.grid(True)\n",
    "\n",
    "fed_avg_model_rounds = list(fed_avg_model_results.keys())\n",
    "\n",
    "fed_avg_accuracies = [fed_avg_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_avg_model_rounds]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Round')\n",
    "plt.grid(True)\n",
    "\n",
    "fed_avg_global_losses = [fed_avg_model_results[round][\"global_loss\"] for round in fed_avg_model_rounds]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for Each Round')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedProx experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProxFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        global_params = copy.deepcopy(self.net).parameters()\n",
    "        proxima_train(self.net, self.trainloader, EPOCHS, config[\"proximal_mu\"], global_params)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedProxFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_prox_result = {}\n",
    "\n",
    "fed_prox_model_results = {}\n",
    "\n",
    "class ModifiedFedProx(ModifiedFedAvg):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        proximal_mu: float,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_evaluate=fraction_evaluate,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_evaluate_clients=min_evaluate_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            evaluate_fn=evaluate_fn,\n",
    "            on_fit_config_fn=on_fit_config_fn,\n",
    "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "            accept_failures=accept_failures,\n",
    "            initial_parameters=initial_parameters,\n",
    "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        )\n",
    "        self.proximal_mu = proximal_mu\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ModifiedFedProx\"\n",
    "    \n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> list[tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\n",
    "\n",
    "        Sends the proximal factor mu to the clients\n",
    "        \"\"\"\n",
    "        # Get the standard client/config pairs from the FedAvg super-class\n",
    "        client_config_pairs = super().configure_fit(\n",
    "            server_round, parameters, client_manager\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs with the proximal factor mu added\n",
    "        return [\n",
    "            (\n",
    "                client,\n",
    "                FitIns(\n",
    "                    fit_ins.parameters,\n",
    "                    {**fit_ins.config, \"proximal_mu\": self.proximal_mu},\n",
    "                ),\n",
    "            )\n",
    "            for client, fit_ins in client_config_pairs\n",
    "        ]\n",
    "    \n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        \n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) *2\n",
    "        print(f\"total size: {total_size}\")\n",
    "        \n",
    "        if fed_prox_result.get(server_round):\n",
    "            fed_prox_result[server_round][\"total_size\"] = total_size\n",
    "        else:\n",
    "            fed_prox_result[server_round] = {\"total_size\": total_size}\n",
    "        \n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss\n",
    "\n",
    "        if fed_prox_result.get(server_round):\n",
    "            fed_prox_result[server_round][\"total_loss\"] = total_loss\n",
    "        else:\n",
    "            fed_prox_result[server_round] = {\"total_loss\": total_loss}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "    \n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        \n",
    "        if server_round in fed_prox_model_results:  \n",
    "            expand_fed_prox_model_results= {**fed_prox_model_results[server_round], \"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        else:\n",
    "            expand_fed_prox_model_results= {\"global_loss\": eval_res[0], \"global_metrics\": eval_res[1]}\n",
    "        \n",
    "        fed_prox_model_results[server_round] = expand_fed_prox_model_results\n",
    "        \n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=20, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07208152244091034, {'accuracy': 0.1}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m [Client 3] fit, config: {'proximal_mu': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m Epoch 1: train loss 0.055783577263355255, accuracy 0.3167812015074263\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m [Client 5] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 1: train loss 0.027075104415416718, accuracy 0.6374853113983548\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m Epoch 2: train loss 0.01405999343842268, accuracy 0.8160919540229885\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m Epoch 3: train loss 0.040982700884342194, accuracy 0.5114165373531367\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 2: train loss 0.015665503218770027, accuracy 0.8398942420681551\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m Epoch 2: train loss 0.035856012254953384, accuracy 0.49493365500603137\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m Epoch 4: train loss 0.009830549359321594, accuracy 0.8797208538587848\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34081)\u001b[0m Epoch 5: train loss 0.03345874696969986, accuracy 0.6140545333628907\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m Epoch 3: train loss 0.03174716606736183, accuracy 0.5698431845597105\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m Epoch 5: train loss 0.008755607530474663, accuracy 0.8988095238095238\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m Epoch 4: train loss 0.006838618777692318, accuracy 0.9218241042345277\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m Epoch 4: train loss 0.029188411310315132, accuracy 0.6139927623642943\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m Epoch 4: train loss 0.012618716806173325, accuracy 0.8709791863765374\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m Epoch 5: train loss 0.025978082790970802, accuracy 0.6662243667068758\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 280903200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.07209435589313506, {'accuracy': 0.1}, 90.70528550003655)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m Epoch 5: train loss 0.010927748866379261, accuracy 0.885879848628193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m [Client 5] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 1: train loss 0.049546632915735245, accuracy 0.4007980492130348\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m [Client 0] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m Epoch 1: train loss 0.030213627964258194, accuracy 0.5572855464159812\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 2: train loss 0.04030464589595795, accuracy 0.5213921525160718\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 3: train loss 0.03473940119147301, accuracy 0.598758590113057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m Epoch 2: train loss 0.014599381014704704, accuracy 0.853003784295175\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34078)\u001b[0m Epoch 4: train loss 0.009711782447993755, accuracy 0.8844417077175698\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34082)\u001b[0m Epoch 5: train loss 0.027744753286242485, accuracy 0.6696962979383728\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34079)\u001b[0m Epoch 4: train loss 0.027585431933403015, accuracy 0.5850470035252644\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m Epoch 4: train loss 0.023142103105783463, accuracy 0.7138721351025332\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m Epoch 5: train loss 0.020234351977705956, accuracy 0.7564535585042219\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 6 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 280903200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.07280328328609467, {'accuracy': 0.1}, 190.16454150003847)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 6 clients (out of 6)\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m Epoch 5: train loss 0.00804327055811882, accuracy 0.9161542100283823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 6 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 6 clients (out of 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m [Client 1] fit, config: {'proximal_mu': 0.1}\n",
      "\u001b[36m(ClientAppActor pid=34080)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m [Client 5] fit, config: {'proximal_mu': 0.1}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m /Users/macbook/Desktop/L361/L361_Project/.conda/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=34077)\u001b[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "net = Net().to(DEVICE)\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(testloader, net)\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=ModifiedFedProx(proximal_mu=0.1, evaluate_fn=evaluate_fn),\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_prox_data_heterogenity_result.p', 'wb') as file:\n",
    "    pickle.dump(fed_prox_result, file)\n",
    "\n",
    "with open(f'results/fed_prox_model_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_prox_model_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_prox_rounds = list(fed_prox_result.keys())\n",
    "fed_prox_sizes = [fed_prox_result[round][\"total_size\"] for round in fed_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_prox_rounds, fed_prox_sizes, marker='o', linestyle='-', color='b', label='FedProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Size of Parameters (bytes)')\n",
    "# plt.title('Total Size of Parameters for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_prox_losses = [fed_prox_result[round][\"total_loss\"] for round in fed_prox_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_prox_rounds, fed_prox_losses, marker='o', linestyle='-', color='b', label='FedProx')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Total Loss')\n",
    "# plt.title('Total Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "# fed_prox_model_rounds = list(fed_prox_model_results.keys())\n",
    "# fed_prox_accuracies = [fed_prox_model_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(fed_part_prox_model_rounds, fed_part_prox_accuracies, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_prox_global_losses = [fed_prox_model_results[round][\"global_loss\"] for round in fed_prox_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(fed_part_prox_model_rounds, fed_part_prox_global_losses, marker='o', linestyle='-', color='b', label='FedPartProx')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')   \n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='g', label='FedAvg')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedMoon experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedMoonNoFreezeFlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model_dir = \"models\"\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        parameters = get_parameters(self.net)\n",
    "        trainable_layer = config[\"trainable_layers\"]\n",
    "        self._save_model_state()\n",
    "        \n",
    "        if trainable_layer == -1:\n",
    "            return parameters\n",
    "        \n",
    "        trained_layer = [parameters[trainable_layer*2], parameters[trainable_layer*2 +1]]\n",
    "        return trained_layer\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "\n",
    "        # load previous model\n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            prev_model = copy.deepcopy(self.net)\n",
    "        else:\n",
    "            # initialise and load params from model_dir\n",
    "            prev_model = type(self.net)() \n",
    "            prev_model.load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # update params for current model (loading global params)\n",
    "        set_parameters(self.net, parameters)\n",
    "\n",
    "        # create global model (same params that were just loaded)\n",
    "        global_model = type(self.net)()\n",
    "        global_model.load_state_dict(self.net.state_dict())\n",
    "        global_model.to(DEVICE)\n",
    "        \n",
    "        train_moon(self.net, self.trainloader, global_model, prev_model, EPOCHS, 5, 0.5)\n",
    "\n",
    "        # save current model \n",
    "        if not os.path.exists(os.path.join(self.model_dir, str(self.partition_id))):\n",
    "            os.makedirs(os.path.join(self.model_dir, str(self.partition_id)))\n",
    "        torch.save(\n",
    "            self.net.state_dict(),\n",
    "            os.path.join(self.model_dir, str(self.partition_id), \"prev_net.pt\"),\n",
    "        )\n",
    "\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test_moon(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = MoonNet().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FedMoonNoFreezeFlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import sys\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "def get_parameters_size(params: Parameters) -> int:\n",
    "    size = sys.getsizeof(params)  # Base size of the dataclass instance\n",
    "    size += sys.getsizeof(params.tensor_type)  # Size of the string\n",
    "    size += sys.getsizeof(params.tensors)  # Size of the list container\n",
    "    size += sum(sys.getsizeof(tensor) for tensor in params.tensors)  # Size of each bytes object\n",
    "    return size\n",
    "\n",
    "fed_moon_no_freeze_result = {}\n",
    "fed_moon_model_no_freeze_results = {}\n",
    "\n",
    "# basically same as normal FedAvg, just added freezing and modified result dict names\n",
    "class FedMoonNoFreeze(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        evaluate_fn: Optional[\n",
    "            Callable[\n",
    "                [int, NDArrays, dict[str, Scalar]],\n",
    "                Optional[tuple[float, dict[str, Scalar]]],\n",
    "            ]\n",
    "        ] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        inplace: bool = True,\n",
    "        layer_update_strategy: str = \"sequential\",\n",
    "        \n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.inplace = inplace\n",
    "        self.layer_training_sequence = []\n",
    "        self.training_sequence_index = 0\n",
    "        self.latest_parameters = initial_parameters\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedMoon\"\n",
    "    \n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "   \n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[tuple[float, dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "        if self.evaluate_fn is None:\n",
    "            # No evaluation function provided\n",
    "            return None\n",
    "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "        loss, metrics = eval_res\n",
    "\n",
    "        if server_round in fed_moon_model_no_freeze_results:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_model_no_freeze_results[server_round], \"global_loss\": loss, \"global_metrics\": metrics}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"global_loss\": loss, \"global_metrics\": metrics}\n",
    "\n",
    "        fed_moon_model_no_freeze_results[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "    def configure_fit(\n",
    "        # includes layer freezing\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        config = {}\n",
    "        \n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        \n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            fit_configurations.append((client, FitIns(parameters, config)))\n",
    "\n",
    "        self.training_sequence_index = self.training_sequence_index + 1\n",
    "        \n",
    "        return fit_configurations\n",
    "    \n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "\n",
    "        # get size of parameters in bytes\n",
    "        total_size = 0\n",
    "        for client, fit_res in results:\n",
    "            total_size += get_parameters_size(fit_res.parameters) * 2\n",
    "        \n",
    "        if server_round in fed_moon_no_freeze_result:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_no_freeze_result[server_round], \"total_size\": total_size}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"total_size\": total_size}\n",
    "\n",
    "        fed_moon_no_freeze_result[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        \n",
    "        aggregated_weights = aggregate(weights_results)\n",
    "        \n",
    "        self.latest_parameters = ndarrays_to_parameters(aggregated_weights)\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        return self.latest_parameters, metrics_aggregated\n",
    "\n",
    "    \n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        total_loss = 0\n",
    "        for _, evaluate_res in results:\n",
    "            total_loss += evaluate_res.loss \n",
    "\n",
    "\n",
    "        if server_round in fed_moon_no_freeze_result:\n",
    "            expand_fed_moon_no_freeze_result= {**fed_moon_no_freeze_result[server_round], \"total_loss\": total_loss}\n",
    "        else:\n",
    "            expand_fed_moon_no_freeze_result= {\"total_loss\": total_loss}\n",
    "\n",
    "        fed_moon_no_freeze_result[server_round] = expand_fed_moon_no_freeze_result\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FedMOON\n",
    "\n",
    "\n",
    "_, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
    "net = MoonNet().to(DEVICE)\n",
    "evaluate_fn = get_evaluate_fn_moon(testloader, net)\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=NUM_OF_ROUNDS)\n",
    "    return ServerAppComponents(\n",
    "        config=config,\n",
    "        strategy=FedMoonNoFreeze(\n",
    "            evaluate_fn=evaluate_fn\n",
    "        )\n",
    "    )\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/fed_moon_no_freeze_data_heterogenity_result.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_no_freeze_result, file)\n",
    "\n",
    "with open(f'results/fed_moon_model_no_freeze_data_heterogenity_results.p', 'wb') as file:\n",
    "    pickle.dump(fed_moon_model_no_freeze_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fed_moon_rounds = list(fed_moon_no_freeze_result.keys())\n",
    "# fed_moon_sizes = [fed_moon_no_freeze_result[round][\"total_size\"] for round in fed_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_sizes, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_sizes, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_rounds, fed_prox_sizes, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_sizes, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_rounds, fed_moon_sizes, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_sizes, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Communication Cost (bytes)')\n",
    "# plt.title('Communication Cost for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_losses = [fed_moon_no_freeze_result[round][\"total_loss\"] for round in fed_moon_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_rounds, fed_avg_losses, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_rounds, fed_part_avg_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_rounds, fed_prox_losses, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_rounds, fed_part_prox_losses, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_rounds, fed_moon_losses, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_rounds, fed_part_moon_losses, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Aggregate Client Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_model_rounds = list(fed_moon_model_no_freeze_results.keys())\n",
    "# fed_moon_accuracies = [fed_moon_model_no_freeze_results[round][\"global_metrics\"][\"accuracy\"] for round in fed_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_accuracies, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_accuracies, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_model_rounds, fed_prox_accuracies, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_accuracies, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_model_rounds, fed_moon_accuracies, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_accuracies, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Global Model Accuracy for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# fed_moon_global_losses = [fed_moon_model_no_freeze_results[round][\"global_loss\"] for round in fed_moon_model_rounds]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(fed_avg_model_rounds, fed_avg_global_losses, marker='o', linestyle='-', color='b', label='FedAvg')\n",
    "# plt.plot(fed_part_avg_model_rounds, fed_part_avg_global_losses, marker='o', linestyle='-', color='r', label='FedPartAvg')\n",
    "# plt.plot(fed_prox_model_rounds, fed_prox_global_losses, marker='o', linestyle='-', color='g', label='FedProx')\n",
    "# plt.plot(fed_part_prox_model_rounds, fed_part_prox_global_losses, marker='o', linestyle='-', color='y', label='FedPartProx')\n",
    "# plt.plot(fed_moon_model_rounds, fed_moon_global_losses, marker='o', linestyle='-', color='c', label='FedMoon')\n",
    "# plt.plot(fed_part_moon_model_rounds, fed_part_moon_global_losses, marker='o', linestyle='-', color='purple', label='FedPartMoon')\n",
    "# plt.xlabel('Round')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Global Model Loss for Each Round')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
